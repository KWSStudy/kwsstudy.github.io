<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MongoDB on Korea Web Service Study Group</title>
    <link>http://kwsstudy.github.io/tags/mongodb/</link>
    <description>Recent content in MongoDB on Korea Web Service Study Group</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 11 Dec 2016 12:00:00 +0900</lastBuildDate>
    <atom:link href="http://kwsstudy.github.io/tags/mongodb/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>GridFS</title>
      <link>http://kwsstudy.github.io/post/GridFS/</link>
      <pubDate>Sun, 11 Dec 2016 12:00:00 +0900</pubDate>
      
      <guid>http://kwsstudy.github.io/post/GridFS/</guid>
      <description>

&lt;h3 id=&#34;목표:0aad788b2f0ebd8f12eb3189b245d45e&#34;&gt;목표&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;GridFS의 개념익히기&lt;/li&gt;
&lt;li&gt;java-mongodb 드라이버를 이용한 간단한 몽고디비 연동 및 GridFS 샘플&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;책에-나온-gridfs:0aad788b2f0ebd8f12eb3189b245d45e&#34;&gt;책에 나온 GridFS&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;어플리케이션에서 이미지, 섬네일, 비디오등 이진파일을 저장하기위해 파일 시스템에 의지.&lt;/li&gt;
&lt;li&gt;파일 시스템은 액세스를 빠르게 해주지만, 수 만건 이상의 파일 관리시에 데이터 구조에 혼란을 초래함.&lt;/li&gt;
&lt;li&gt;파일의 메타 데이터는 데이터 베이스에 저장할 경우 실제 파일과 메타데이터간의 정확한 백업이 복잡해짐.&lt;/li&gt;
&lt;li&gt;파일 구조와 백업을 간단히 하기위해 파일을 데이터 베이스 자체에 저장하는 것이 합리적일 경우 사용.&lt;/li&gt;
&lt;li&gt;파일 하나당 하나의 도큐먼트를 사용하는 것은 소량(1MB이하)의 이진객체에 적합.&lt;/li&gt;
&lt;li&gt;대용량의 파일은 GridFS를 사용.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;gridfs의-개념:0aad788b2f0ebd8f12eb3189b245d45e&#34;&gt;GridFS의 개념&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;GridFS는 BSON 문서 크기 제한인 16MB를 초과하는 파일을 저장하고 검색하기위한 기능.&lt;/li&gt;
&lt;li&gt;GridFS는 파일을 하나의 문서에 저장하는 대신 파일을 여러 부분의 chunk로 나누고 각 chunk를 별도의 문서로 저장한다.&lt;/li&gt;
&lt;li&gt;기본적으로 GridFS는 255KB의 chunk를 사용한다.&lt;/li&gt;
&lt;li&gt;GridFS는 파일 청크 콜렉션(bucket.chunks), 파일 메타 데이터 콜렉션(bucket.files)을 사용하여 파일을 저장한다.&lt;/li&gt;
&lt;li&gt;GridFS에 파일을 쿼리하면, 드라이버는 필요에 따라 청크를 재조합한다.&lt;/li&gt;
&lt;li&gt;GridFS를 통해 저장된 파일에 대해 범위 쿼리를 수행 할 수 있다.&lt;/li&gt;
&lt;li&gt;비디오 또는 오디오 파일의 중간으로 건너 뛰는 것과 같이 파일의 임의 섹션에서 정보에 액세스 할 수도 있다.&lt;/li&gt;
&lt;li&gt;GridFS는 16MB를 초과하는 파일을 저장할 때, 전체 파일을 메모리에 로드하지 않고 액세스하려는 파일을 저장 할 수있다.&lt;/li&gt;
&lt;li&gt;버전 2.4.10에서 변경 : 기본 청크 크기가 256KB에서 255KB로 변경됨.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;gridfs-사용시기:0aad788b2f0ebd8f12eb3189b245d45e&#34;&gt;GridFS 사용시기&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;시스템보다 큰 파일을 저장하는 것이 MongoDB 데이터베이스에서 더 효율적일 수 있다.&lt;/li&gt;
&lt;li&gt;파일 시스템이 디렉토리의 파일 수를 제한하는 경우, GridFS를 사용하여 필요한만큼의 파일을 저장할 수 있다.&lt;/li&gt;
&lt;li&gt;일부 정보에 액세스하려는 경우 GridFS를 사용하여 전체 파일을 메모리로 읽지 않고 필요한 파일 섹션을 호출 할 수 있다.&lt;/li&gt;
&lt;li&gt;파일 및 메타 데이터를 여러 시스템 및 시설에 자동으로 동기화 및 배포하려는 경우 GridFS를 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;분산 된 복제 세트를 사용할 때, MongoDB는 여러 mongod 인스턴스와 기능에 파일과 메타 데이터를 자동으로 배포 할 수 있다.&lt;/li&gt;
&lt;li&gt;전체 파일의 내용을 원자 적으로 업데이트해야하는 경우 GridFS 사용을 권장하지 않음.&lt;/li&gt;
&lt;li&gt;대안으로 각 파일의 여러 버전을 저장하고 메타 데이터에 파일의 현재 버전을 지정 한다.&lt;/li&gt;
&lt;li&gt;새 파일을 업로드 한 후 &amp;ldquo;최신&amp;rdquo;상태를 나타내는 메타 데이터 필드를 업데이트하고 필요하면 이전 버전을 제거.&lt;/li&gt;
&lt;li&gt;파일 크기가 16MB보다 작 으면 GridFS를 사용하는 대신 단일 문서에 파일을 수동으로 저장하는 것이 좋다.&lt;/li&gt;
&lt;li&gt;BinData 데이터 형식을 사용하여 이진 데이터를 저장할 수 있다.&lt;/li&gt;
&lt;li&gt;BinData 사용에 대한 자세한 내용은 &lt;a href=&#34;https://docs.mongodb.com/manual/reference/bson-types/&#34;&gt;드라이버 설명서&lt;/a&gt;를 참조하십시오.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;몽고디비-연동-및-gridfs-샘플:0aad788b2f0ebd8f12eb3189b245d45e&#34;&gt;몽고디비 연동 및 GridFS 샘플&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;java-mongodb 드라이버연동&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//클라이언트 연결
MongoClient client = new MongoClient(&amp;quot;localhost&amp;quot;);
//데이터베이스 선택
MongoDatabase database = client.getDatabase(&amp;quot;tutorial&amp;quot;);
//컬렉션 선택
MongoCollection&amp;lt;Document&amp;gt; collection =  database.getCollection(&amp;quot;numbers&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;GridFS 샘플&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//GridFS가 생성될 컬렉션 이름
final String bucket = &amp;quot;test&amp;quot;;
//GridFS를 이용해 저장할 파일명
final String filename = &amp;quot;test.JPG&amp;quot;;		 
//bucket명으로 지정한 GridFS연결 생성
GridFSBucket gridFSBucket = GridFSBuckets.create(database,bucket);
//사용자 정의 metadata에 저장될 샘플 BsonDocument
ObjectId etag = new ObjectId();
BsonDocument metadata = new BsonDocument();
metadata.put(&amp;quot;_etag&amp;quot;, new BsonObjectId(etag));
 
GridFSUploadOptions options = new GridFSUploadOptions().metadata(Document.parse(metadata.toJson()));
//GridFS를 이용해 저장할 파일 InputStream 생성
InputStream sourceStream = MongoConnector.class.getResourceAsStream(filename);

//GridFS를 이용해 파일 저장 후 _id값 받아오기	         
ObjectId _id = gridFSBucket.uploadFromStream( filename, sourceStream, options);
//저장된 _id값 출력
System.out.println(_id);
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;mongodb에서 확인&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//생성된 GridFS 컬렉션 확인
&amp;gt; show tables;
numbers
test.chunks
test.files
//생성된 chunk 수 확인
&amp;gt; db.test.chunks.count()
25
//저장된 file 정보 확인
&amp;gt; db.test.files.find().pretty()
{
        &amp;quot;_id&amp;quot; : ObjectId(&amp;quot;58477396f034dd1b840b32d4&amp;quot;),
        &amp;quot;filename&amp;quot; : &amp;quot;test.JPG&amp;quot;,
        &amp;quot;length&amp;quot; : NumberLong(6341811),
        &amp;quot;chunkSize&amp;quot; : 261120,
        &amp;quot;uploadDate&amp;quot; : ISODate(&amp;quot;2016-12-07T02:27:35.304Z&amp;quot;),
        &amp;quot;md5&amp;quot; : &amp;quot;48b2a854b5deb75370fcaaef52c865e6&amp;quot;,
        &amp;quot;metadata&amp;quot; : {
                &amp;quot;_etag&amp;quot; : ObjectId(&amp;quot;58477396f034dd1b840b32d3&amp;quot;)
        }
}
&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;저장된 GridFS를 이용해 파일 가져오기&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;//bucket명으로 지정한 GridFS연결 생성
GridFSBucket downloadGridFs = GridFSBuckets.create(database,bucket);
//지정된 파일명에 해당하는 id가져오기
ObjectId fid = downloadGridFs.find(Filters.eq(&amp;quot;filename&amp;quot;, filename)).first().getObjectId();
//가져온 파일을 d:/mongo.JPG에 저장
downloadGridFs.downloadToStream(fid, new FileOutputStream(new File(&amp;quot;d:/mongo.JPG&amp;quot;)));
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/KWSStudy/Mongodb/blob/master/src/main/java/com/mongoDb/MongoConnector.java&#34;&gt;샘플소스 전체 보기&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ko.m.wikipedia.org/wiki/이진_파일&#34;&gt;이진 데이터&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>배포와 관리</title>
      <link>http://kwsstudy.github.io/post/%EB%B0%B0%ED%8F%AC%EC%99%80-%EA%B4%80%EB%A6%AC/</link>
      <pubDate>Sun, 11 Dec 2016 11:00:00 +0900</pubDate>
      
      <guid>http://kwsstudy.github.io/post/%EB%B0%B0%ED%8F%AC%EC%99%80-%EA%B4%80%EB%A6%AC/</guid>
      <description>

&lt;h3 id=&#34;목표:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;목표&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;배포 고려사항 및 하드웨어 필요사항&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;관리, 백업, 보안 방법&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;성능 문제 해결 방법&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;배포-환경:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;배포 환경&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;아키텍처&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;몽고디비는 가상 주소공간으로 매핑하기 때문에 충분한 메모리를 확보할 수 있는 64비트 운영 체제를 사용하자.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://ko.m.wikipedia.org/wiki/엔디언&#34;&gt;리틀 엔디언&lt;/a&gt; 서버에서 실행해야한다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CPU&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;몽고디비는 cpu연산이 많은 어플리케이션이 아니다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;램&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;작업 데이터의 크기가 램 용량을 넘어서게 되면 성능 저하가 심각해 진다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;자주 사용하는 인덱스와 작업 데이터를 램이 수용할 수 있도록 충분한 램을 확보하자.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;디스크&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;몽고디비에 쓰기를 할 때 서버가 매 60초마다 디스크에 동기화를 하기 때문에 디스크 속도가 느리면 성능이 저하될수 있다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;읽기 쓰기를 수행할때 물리적인 메모리가 다찰 때까지 새로운 가상메모리 페이지를 램으로 읽어들인다. 디스크가 빠르면 이작업이 빨라진다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;파일 시스템&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ext4, xfs 파일 시스템은 몽고디비에서 빈번하게 일어나는 선할당의 속도가 빨라진다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;파일 디스크립터&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;실제 서비스에서 모자라게 되는 일이 없도록 제한값을 높게잡고 시작한다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;클럭&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;복제는 시스템 클럭 차이에 민감하다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;복제셋의 노드를 호스팅하는 서버의 클럭이 서로 달라지게 되면 복제가 올바르게 작동하지 못할 수도 있다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;각 서버에서 &lt;a href=&#34;https://ko.m.wikipedia.org/wiki/네트워크_타임_프로토콜&#34;&gt;NTP&lt;/a&gt;를 사용해서 클럭을 동기화 할 필요가 있다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;클라우드&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;클라우드를 이용하게 되면 메모리 제한에서 자유로울수 없다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;클라우드는 블랙박스 이기 때문에, 서비스 문제를 분석하고 해결할 수 있는 방법이 업다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;클라우드의 디스크는 높은 수준의 처리율을 제공하지 않는다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;서버-설정:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;서버 설정&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;구성 선택&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;최소한의 권장 배포 구성은 세 멤버로 이루어진 복제셋이다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;저널링&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;2.0부터 디폴트로 사용된다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;모든 쓰기를 핵심 데이터 파일에 쓰기 전에 저널에 먼저 쓴다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;예상치 않게 셧다운 되었을 때 신속하고 정확하게 온라인 상태로 되돌아오게 해준다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;저널링을 사용하면 쓰기 성능 옵션이 저하된다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;100미리초의 동기화 시간이 있기 때문에 100미리초 만큼의 연산이 소실될수 있다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;데이터-import-export:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;데이터 import, export&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Mongoimport&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;JSON, CSV, TSV 파일을 들여오기 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Mongoexport&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;컬렉션의 모든 데이터를 JSON, CSV파일로 내보낼수 있다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;보안:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;보안&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;안전한 환경&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;모든 데이터베이스 클라이언트는 모든 복제셋 노드에 연결할 수 있어야 한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;샤드 클러스터는 부분적으로 복제셋으로 이루어져 있다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;인증 API&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;인증 시작을 위해서는 admin 데이터 베이스에 사용자를 추가해야한다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;복제셋 인증&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;패스워드 역할을 하는 최소한 6개의 문자로 이루어진 base64파일을 생성해야한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;keyFile 옵션을 사용해 패스워드 파일의 위치를 지정한상태로 복제셋 멤버를 실행&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;샤딩 인증&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;복제셋과 동일&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;모니터링과-진단:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;모니터링과 진단&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;로깅&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;logpath, -v 옵션을 이용해 로그를 저장한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;logappend 옵션을 사용하면, 로그를 새로쓰지 않고 추가한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;logrotate 명령을 실행하면 로그 파일을 주기적으로 순환한다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;모니터링-도구:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;모니터링 도구&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;serverStatus&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;서버의 상태를 알려준다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.mongodb.com/manual/reference/method/db.serverStatus/#db.serverStatus&#34;&gt;메뉴얼 참조&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;top&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;연산이 평균적으로 얼마나 오래 실행되고 있는지를 알려준다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.mongodb.com/manual/reference/command/top/#dbcmd.top&#34;&gt;메뉴얼 참조&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;db.currentOp()&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;몽고디비가 현재 무엇을 수행하고 있는지 알려준다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.mongodb.com/manual/reference/method/db.currentOp/#db.currentOp&#34;&gt;메뉴얼 참조&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;MONGOSTAT&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;다른 명령어는 순간의 내용이지만 MONGOSTAT은 실시간 액티비티를 제공한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.mongodb.com/manual/reference/program/mongostat/&#34;&gt;메뉴얼 참조&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;웹콘솔&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;시각화된 인터페이스를 제공&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&amp;ndash;rest 옵션 + 몽고디비를 실행중인 포트 + 1000하면 사용가능&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;모니터링-외부-어플리케이션:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;모니터링 외부 어플리케이션&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nagios.org&#34;&gt;나기오스&lt;/a&gt;, &lt;a href=&#34;http://munin-monitoring.org&#34;&gt;뮤닌&lt;/a&gt;등이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;진단도구:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;진단도구&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;mongosniff&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;클라이언트로부터 전송되는 패킷을 검사하고 알기쉽게 추출.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;bsondump&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;BSON 원파일을 검사할수 있다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;유지보수:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;유지보수&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;백업과 복구&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;mongodump, mongorestore를 이용하거나, 데이터파일을 카피.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;압축과 수리&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;mongod &amp;ndash;repair를 사용하여 서버의 모든 데이터베이스를 수리할수 있다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;데이터베이스 단위의 수리는 db.repairDatabase()를 사용한다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;업그레이드&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;가능한 최신 안정버전을 업그레이드 하여 사용하도록 하자.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;성능문제-해결:894bb1f58eae2986a0c76f97e80f5f02&#34;&gt;성능문제 해결&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;인덱스와 쿼리 효율성&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;성능문제 발생시 가장먼저 확인해야 하는것이 인덱스.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;중복된 인덱스로 인해 디스크 공간과 램이 더많이 필요해 지면, 쓰기연산에 더 많은 작업이 필요해진다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;램추가&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;인덱스조정이 항상 해결책은 아니다. 데이터가 메모리용량보다 많으면 디스크 액세스가 자주 발생해 속도가 저하될수 있다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;dataSize와 storageSize의 크기 차이를 잘 확인해야함.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;storageSize 가 너무 크면 디스크 파편화로 성능이 저하될수 있다. 이 파편화로 실제 필요한것 이상의 램을 사용할수 있다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;디스크 성능 향상&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RAID를 구성하거나 SSD를 구입하자.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;수평적 확장&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;전체 작업 데이터를 어느 한서버의 물리적인 램이 수용할수 없을때, 어느 한서버에 쓰기부하가 너무 클때 샤드클러스터를 구축하자.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;전문가의 도움&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;그래도 안되면 전문가를 부르자&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>샤딩</title>
      <link>http://kwsstudy.github.io/post/%EC%83%A4%EB%94%A9/</link>
      <pubDate>Sun, 04 Dec 2016 12:00:00 +0900</pubDate>
      
      <guid>http://kwsstudy.github.io/post/%EC%83%A4%EB%94%A9/</guid>
      <description>

&lt;h3 id=&#34;9-1-1-샤딩이란:d36b31b274746e47eb4599251e059e00&#34;&gt;9.1.1 샤딩이란&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;데이터의 크기가 커지고 애플리케이션에서 읽기와 쓰기 처리량이 늘어남에 따라 현재의 서버로는 충분치 않은 상황이 올 수도 있다.(램이나 CPU 코어가 충분치 않을 수도있다.)&lt;/li&gt;
&lt;li&gt;대이터 크기가 늘어남에 따라 하나의 디스크나 RAID(&lt;a href=&#34;https://ko.wikipedia.org/wiki/RAID&#34;&gt;https://ko.wikipedia.org/wiki/RAID&lt;/a&gt;) 어레이에 대량의 데이터를 저장하고 백업하는 것이 현실적으로 불가능해질 수도있다.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;데이터 베이스를 위해 현재 가용한 서버나 가상 하드웨어를 계속해서 사용하려면 하나 이상의 서버에 데이터베이스를 분산해야하는데 이것이 샤딩을 통해 이루어진다.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;상당수의 대규모 웹 애플리케이션은 여러개의 MySQL 데이터베이스에 걸쳐서 부하를 분산하는 _수동적인 샤딩_을 구현한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;수동적인 샤딩의 수행 : 데이터베이스를 룩업 데이터베이스로 지정함으로써 수행할 수 있다. 예 ) 매우 방대한 레코드를 가지고 있는 유저 테이블을 어러 개의 데이터베이스에 분산하였다고 가정하였을때 룩업데이터베이스는 각 유저 ID 혹은 일정 범위에 속하는 유저 ID를 해당 샤드에 매핑하는 메타데이터를 갖는다. 이로써 유저에 대한 쿼리는 두쿼리로 이루어진다 첫번째 유저의 샤드 위치를 얻기위해 룩업데이터베이스를 참조 두번째 유저 데이터를 가지고 있는 개별샤드에 대해 수행된다.&lt;/li&gt;
&lt;li&gt;수동적인 샤딩의 문제점 1 : 부하문제는 해결하지만, 데이터를 옮기는 것이 어렵다 하나의 샤드에 과부하가 걸리면 데이터를 다른 샤드로 옮기는 것이 수작업으로 이루어진다. ( 하나의 샤드에 과부하가 걸리면 데이터를 다른 샤드로 옮기는 것이 수작업으로 이루어진다. )&lt;/li&gt;
&lt;li&gt;수동적인 샤딩의 문제점 2 : 읽기와 쓰기를 라우팅하고, 전체적으로 데이터베이스를 관리하는 애플리케이션 코드를 작성하고 유지하기가 쉽지 않다는 점이다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;즉 수동으로 데이터 베이스 샤딩을 해본 사람이라면 누구나 말하듯이 이것을 제대로 하기가 쉽지 않다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;MongoDB는 많은 부분에서 이 문제를 해결하기 위해 만들어졌다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;MongoDB는 샤딩 전과 후에 애플리케이션에 대한 인터페이스가 같도록 설계되어있다. 이것은 데이터베이스가 샤드 구조로 변경되더라도 애플리케이션 코드를 수정할 필요가 거의 없다는 점을 의미한다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;샤딩을-해야-할-때:d36b31b274746e47eb4599251e059e00&#34;&gt;샤딩을 해야 할 때&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;인덱스와 작업중인 데이터를 램에 유지하는 것이다. 애플리케이션의 데이터가 점점 제한없이 커진다면 그 데이터가 더 이상 램에 수용될 수 없는 시점이 온다. 즉 어떤 서버도 무한대의 램을 가질 수는 없는 법 따라서 결국에는 필요하게 된다.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;어떤 경우이건 기존의 시스템을 샤딩하고자 하는 결정은 디스크 활동, 시스템 부하, 그리고 언제나 중요한 데이터 대 램의 비율을 정기적으로 분석한 결과를 항상 바탕을 두어야한다&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;9-1-2-샤딩-작동-방식:d36b31b274746e47eb4599251e059e00&#34;&gt;9.1.2 샤딩 작동 방식&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;샤딩 구성요소&lt;/strong&gt;
  - page 255 그림 참조
  - 샤드 : MongoDB 샤드 클러스터는 데이터를 &lt;strong&gt;하나 혹은 그 이상의 샤드에 걸쳐서 분산&lt;/strong&gt; 저장한다. 각 샤드는 MongoDB의 복제 셋으로 클러스터의 전체 데이터의 일부분을 저장한다. 각 샤드는 그 자체로 복제셋이기 때문에 자신만의 복제 방식을 가지고 있고 자동으로 장애조치를 할 수 있다. 복제셋에서처럼 개별 샤드에 직접 연결할 수는 있으나, 샤드 클러스터의 일부분이기 때문에 클러스터 전체 데이터의 일부만 액세스 할 수있다.
  - MONGOS 라이터 : 각 샤드가 클러스터의 전체 데이터의 일부만을 가지고 있다면 클러스터 전체에 대한 &lt;strong&gt;인터페이스가&lt;/strong&gt; 필요. mongos가 바로 이일을 수행한다. 모든 읽기와 쓰기 요청을 해당 샤드에 보내는 라우터다.
    - mongos는 &lt;strong&gt;지속성이 없는 경량프로세스다&lt;/strong&gt;. 애플리케이션은 로컬 mongos에 연결하고 mongos는 각 샤드에 대한 연결을 관리한다.
  - 설정 서버 : ### mongos 프로세스가 지속성이 없기 때문에 샤드 클러스터의 상태를 어디선가는 유지하고 있어야하는데, 이것이 설정 서버가 하는일이다. 설정 서버는 샤드 클러스터의 메타데이터를 지속적으로 유지한다. 이 데이터는 글로벌 클러스터의 설정사항과 각 데이터베이스, 컬렉션, 각 범위의 데이터의 위치, 그리고 샤드 간 데이터의 전송 내역을 가지고 있는 변동사항 로그다.
    - 설정서버가 가지고 있는 메타데이터는 클러스터가 제대로 동작하고 유지되기 위해 반드시 필요하다. 예 ) mongos 프로세스는 시작할 때마다 설정 서버로부터 메타데이터 복사본을 가지고 온다. 따라서 설정 데이터가 없으면 샤드 클러스터에 대한 일관된 관점을 가질 수 없기에 반드시 필요하다.
    - 그림을 살펴보면 3개의 설정 서버가 있지만 복제셋으로 구성되지 않은 것을 알수있다.mongos 프로세스가 쓰기를 할 때 2단계 커밋을 사용하는데, 이것을 통해 설정 서버들 사이의 일관성이 보장된다( 일관성 보장을 위한 각각의 설정서버들에게 커밋 ). 실제 서비스 시스템에는 정확히 3개의 설정 서버를 실행해야하고 중복성을 위해 서로 다른 별개의 서버에 호스트해야한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;샤딩의 핵심 동작&lt;/strong&gt;
  - 상황 :  스프레드 시트 관리를 위한 클라우드 기반 오피스 제품군을 개발하고 모든 데이터를 MongoDB에 저장한다고 가정해보자(google doc), 사용자는 원하는 대로 문서를 생성할 수 있고, 각 문서는 MongoDB의 spredsheet이라는 컬렉션 내의 한 도큐먼트로 저장된다. 시간이 지남에 따라 애플리케이션의 사용자가 백만여명이 되었다고 가정하였을때 이제 users와 spreadsheets라는 2개의 컬렉션을 생각해보자 users 컬렉션은 관리 할 만하다. 백만여명의 사용자라 할지라도 각 유저 도큐먼트당 1kb 만 잡아도 컬렉션은 대략 1GB이고, 하나의 서버로 쉽게 서비스할 수 있다. 하지만 spreadsheets 컬렉션의 경우 한사용자가 평균적으로 50개의 스프레드시트를 갖고 이 스프레디 시트의 평균 크기가 50kb라면, spreadsheets컬렉션의 크기는 1TB가 된다.
  - &lt;strong&gt;이 애플리케이션이 매우 활발하게 사용된다면 모든 데이터가 램에 수용되길 바랄것이다&lt;/strong&gt;. 이 데이터를 램안에 가지고 있고 읽기와 쓰기를 분산하기 위해서는 &lt;strong&gt;컬렉션을 샤드해야만한다&lt;/strong&gt;. MongoDB가 이런 상황에 대한 해결책을 제공&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;컬렉션애 대한 샤딩&lt;/strong&gt;
  - MongoDB의 샤딩은 범위 기반이다. 샤드된 컬렉션에서 모든 도큐먼트는 해당 키에 대해 어느 범위의 값에 속해야한다는 것을 의미
  - MongoDB는 이러한 범위 내에서 각 도큐먼트를 찾기 위해 이른바 &lt;strong&gt;샤드 키&lt;/strong&gt; 를 사용한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;예) 컬렉션
{
_id : ObjectId(&amp;quot;2g3g5j1h2v2g3h21j1j2j3&amp;quot;)
filename : &amp;quot;spreadsheet-1&amp;quot;,
updated_at : ISODate(&amp;quot;2016-01-01T19:22:42:842Z&amp;quot;),
username : &amp;quot;jihoon&amp;quot;,
data: &amp;quot;raw document data&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;샤드하기위해서는 필드중에 하나를 샤드키로 선언해야한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;_id를 선택한다면 도큐먼트는 오브젝트 id의 범위를 기준으로 분산된다. 하지만 여기서는 id와 username으로 된 복합 샤드키를 선택할 것인데 이유는 잠시후에, 이제 각 범위는 유저네임의 범위가 된다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;청크(chunk) : 청크는 하나의 샤드에 있는 샤드 키 값의 연속적인 범위다. 예) docs 컬렉션에서 샤드 데이터가 A와 B라는 두 샤드에 청크로 나뉘어져 있다면 아래 표와 같게 된다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;시작&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;끝&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;샤드&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;- ∞&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;abbot&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;B&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;abbot&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;dayton&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;A&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;dayton&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;harris&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;B&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;harris&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;norris&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;A&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;norris&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;∞&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;B&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;각 개별 청크가 데이터의 연속적인 범위를 나타내긴 하지만 이 범위들은 어느 샤드에도 나타날 수 있다는 점이다.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;harris&amp;rdquo;에서 시작해서 &amp;ldquo;norris&amp;rdquo;로 끝나는 청크가 A라는 샤드에 존재한다는 말은, 이 범위 안에 들어가는 샤드 키를 갖는 모든 도큐먼트는 샤드 A의 docs컬렉션에서 발견될 수 있다는 말이다. 하지만 이들 도큐먼트가 어떻게 배치 되어있는지와는 전혀 관련이 없다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;분할과 마이그레이션&lt;/strong&gt;
  - 청크의 분할과 마이그레이션은 샤딩 메커니즘의 핵심이다.
  - 샤드 클러스터를 처음 셋업할 때는 단지 하나의 청크만이 존재한다. 그렇다면 어떻게 해서 샤드 클러스터가 어려개의 청크를 가지게 될까?
  - 그것은 청크가 일정한 크기에 도달하면 분할 되기 때문이다. 디폴트 값은 64MB 혹은 100,000 도큐먼트(둘중 어느것이라도 먼저 해당되는 값)
  - MongoDB 샤드 클러스터는 청크를 샤드 사이에서 옮김으로써 균형을 맞춘다. 이것을 마이그레이션이라고 부르고 분할과는 달리 물리적인 작업이다&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;마이그레이션은 밸런서라고 하는 소프트웨어 프로세스에 의해 관리된다.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;가장 많은 수의 청크를 갖는 샤드와 가장 적은 수의 청크를 갖는 샤드간 청크의 개수가 8개 이상 차이가 나면 균형을 일는 작업을 시작한다 이작이 일단 시작되면 청크는 청크 개수가 많은 샤드로부터 적은 샤드로 이동하게 되는데, 두 샤드가 대략 고르게 분포될 때까지 이 작업이 수행된다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;이해가 안가도 걱정마라 다음 섹션에서 실험으로 이해시켜주리리&amp;hellip;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;9-2-샘플-샤딩-클러스터:d36b31b274746e47eb4599251e059e00&#34;&gt;9.2 샘플 샤딩 클러스터&lt;/h3&gt;

&lt;h3 id=&#34;9-2-1-셋업:d36b31b274746e47eb4599251e059e00&#34;&gt;9.2.1 셋업&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;첫번째 단계 : 모든 mongod와 mongos프로세스를 시작하는 것이다&lt;/li&gt;
&lt;li&gt;두번쩨 단계 : 클러스터를 시작하는 일련의 명령을 실행하는 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;샤딩 구성요소 시작&lt;/strong&gt;
  - 2개의 복제셋에 대한 데이터 디렉토리를 생성&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;mkdir /data/rs-a-1
mkdir /data/rs-a-2
mkdir /data/rs-a-3
mkdir /data/rs-b-1
mkdir /data/rs-b-2
mkdir /data/rs-b-3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;folk 옵션 : 프로세스를 데몬으로 실행하도록 한다&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;이제 각 mongod 프로세스를 실행하자&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;sudo mongod --shardsvr --replSet shard-a --dbpath /data/rs-a-1 --port 30000 --logpath /data/rs-a-1.log --fork --nojournal
sudo mongod --shardsvr --replSet shard-a --dbpath /data/rs-a-2 --port 30001 --logpath /data/rs-a-2.log --fork --nojournal
sudo mongod --shardsvr --replSet shard-a --dbpath /data/rs-a-3 --port 30002 --logpath /data/rs-a-3.log --fork --nojournal
두번째 복제셋
sudo mongod --shardsvr --replSet shard-a --dbpath /data/rs-b-1 --port 30100 --logpath /data/rs-b-1.log --fork --nojournal
sudo mongod --shardsvr --replSet shard-a --dbpath /data/rs-b-2 --port 30200 --logpath /data/rs-b-2.log --fork --nojournal
sudo mongod --shardsvr --replSet shard-a --dbpath /data/rs-b-3 --port 30300 --logpath /data/rs-b-3.log --fork --nojournal
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;rs.initiate()
rs.add(&amp;quot;arete:30100&amp;quot;)
rs.add(&amp;quot;arete:30101, {arbiterOnly:true}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;9.3.1 샤드 쿼리 타입
  - 샤드 클러스터에 질의 한다고 가정했을때 질의에 대한 결과를 리턴하기 위해 mongos는 얼마나 많은 샤드에 연결해야할까? 샤드 키가 쿼리 실렉터에 있는지 여부에 달렸다. 설정서버는 키의 범위를 샤드에 대해 매핑한 것을 가지고있다.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>복제(replication)</title>
      <link>http://kwsstudy.github.io/post/%EB%B3%B5%EC%A0%9C/</link>
      <pubDate>Sun, 04 Dec 2016 11:00:00 +0900</pubDate>
      
      <guid>http://kwsstudy.github.io/post/%EB%B3%B5%EC%A0%9C/</guid>
      <description>

&lt;h1 id=&#34;복제-replication:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;복제(replication)&lt;/h1&gt;

&lt;p&gt;복제는 여러 서버 상에서 데이터의 동일한 복사본을 유지하는 방법 &lt;em&gt;(모든 실제 서비스에서는 복제를 적용할 것을 권장)&lt;/em&gt;&lt;br /&gt;
→ 한 대 또는 그 이상의 서버에 이상이 발생하였을 때 애플리케이션의 정상 동작 및 데이터를 안전하게 보존할 수 있음&lt;br /&gt;
※ MongoDB는 &lt;strong&gt;복제 셋(replica set)&lt;/strong&gt;을 생성함으로써 복제를 설정할 수 있음&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;MongoDB in Action 책에는 마스터-슬레이브 복제(master-slave replication) 와 복제 셋(replica set) 두 가지 방식이
있다고 소개되고 있으나 마스터-슬레이브 복제는 3.2 버전부터 Deprecated 되었음&lt;br /&gt;
참조: &lt;a href=&#34;https://docs.mongodb.com/manual/core/master-slave/&#34;&gt;https://docs.mongodb.com/manual/core/master-slave/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;복제-셋-replica-set-의-구성:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;복제 셋(replica set)의 구성&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1대의 프라이머리(primary) 서버&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;클라이언트의 요청을 처리&lt;/li&gt;
&lt;li&gt;데이터에 대한 &lt;strong&gt;쓰기&lt;/strong&gt;, 읽기 가능&lt;/li&gt;
&lt;li&gt;복제 셋에서 쓰기 동작을 하는 유일한 멤버&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;여러 대의 세컨더리(secondary) 서버&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;프라이머리 데이터의 복제 데이터를 가짐&lt;/li&gt;
&lt;li&gt;프라이머리의 oplog에서 하던 동작을 세컨더리의 데이터 셋에 &lt;strong&gt;비동기적&lt;/strong&gt;으로 적용&lt;/li&gt;
&lt;li&gt;프라이머리 서버에 장애가 발생시 세컨더리 서버는 자신들 중 새로운 프라이머리 서버를 선출할 수 있음&lt;/li&gt;
&lt;li&gt;데이터의 읽기만 가능&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;※ 복제 셋의 노드는 최대 &lt;strong&gt;12&lt;/strong&gt;개까지 구성할 수 있다.&lt;/p&gt;

&lt;h2 id=&#34;복제의-작동-방식:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;복제의 작동 방식&lt;/h2&gt;

&lt;h3 id=&#34;오피로그-oplog:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;오피로그(oplog)&lt;/h3&gt;

&lt;p&gt;데이터 복제를 가능하게 함&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;캡드(capped) 컬렉션으로 모든 복제 노드에서 local 이라는 데이터베이스 내에 존재&lt;/li&gt;
&lt;li&gt;데이터에 대한 모든 수정사항을 기록

&lt;ol&gt;
&lt;li&gt;클라이언트가 프라이머리 노드에 대해 쓰기를 할 때마다 세컨더리에서 재생하기 위한 충분한 정보가
프라이머리 노드의 오피로그에 자동으로 추가됨&lt;/li&gt;
&lt;li&gt;쓰기가 세컨더리 노드에 복제되고 나면 쓰기 정보가 세컨더리 노드의 오피로그에도 기록됨&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;오피로그 항목은 BSON 타임스탬프로 인식되고, 모든 세컨더리는 타임스탬프를 이용해서 적용할 최신 항목을 추적&lt;/li&gt;

&lt;li&gt;&lt;p&gt;local 데이터베이스의 &lt;code&gt;oplog.rs&lt;/code&gt;라는 컬렉션에 오피로그가 저장됨&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;※ local 데이터베이스에 저장된 기타 컬렉션&lt;/li&gt;
&lt;li&gt;&lt;code&gt;replset.minvalid&lt;/code&gt; - 복제 셋 멤버의 초기 동기화를 위한 정보&lt;/li&gt;
&lt;li&gt;&lt;code&gt;system.replset&lt;/code&gt; - 복제 셋 설정 도큐먼트를 저장&lt;/li&gt;
&lt;li&gt;&lt;code&gt;me&lt;/code&gt;, &lt;code&gt;slaves&lt;/code&gt; - 쓰기 concern을 구현하는데 사용&lt;/li&gt;
&lt;li&gt;&lt;code&gt;system.indexes&lt;/code&gt; - 인덱스 규격에 대한 정보를 가지고 있는 표준 컬렉션&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;세컨더리가 복제 데이터를 유지하는 프로세스&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;프라이머리 노드에 쓰기 기록&lt;/li&gt;
&lt;li&gt;프라이머리 노드의 오피로그에 추가&lt;/li&gt;
&lt;li&gt;세컨더리 노드가 자신의 오피로그에 프라이머리 노드의 오피로그를 복제&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;세컨더리에서의 상세 프로세스&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;세컨더리 노드가 업데이트 준비가 됨&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;자신의 오프로그에서 가장 최근 항목의 타임스탬프를 검사&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;프라이머리 노드의 오피로그에서 최근 항목의 타임스탬프 이후의 모든 오피로그 항목을 질의&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;질의된 오피로그 항목을 자신의 오프로그에 추가&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;추가된 오프로그의 항목을 자신의 데이터에 적용&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;세컨더리는 롱 폴링(long polling) 방식을 사용하여 프라이머리의 변경 데이터를 즉각적으로 적용하게 됨&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;복제-중지:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;복제 중지&lt;/h3&gt;

&lt;p&gt;세컨더리가 프라이머리 노드의 오피로그에서 동기화할 시점을 발견하지 못하면 복제는 완전히 중지&lt;/p&gt;

&lt;p&gt;※ 발생하는 예외 메시지&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;repl: replication data to stable, halting
Fri Jan 28 14:19:27 [replsecondary] caught SyncException
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;오피로그는 캡드 컬렉션이므로 컬렉션 항목이 시간이 지나면 삭제될 수 있음&lt;/li&gt;
&lt;li&gt;세컨더리 노드가 어떠한 사정으로 프라이머리 노드의 오피로그로 부터 동기화 지점을 찾지 못하면&lt;br /&gt;
→ 세컨더리가 프라이머리의 완벽한 복제본임을 확신할 수 없으므로 복제를 중지할 수 밖에 없음&lt;/li&gt;
&lt;li&gt;유일한 해결책: 프라이머리의 데이터를 처음부터 다시 동기화하는 것&lt;/li&gt;
&lt;li&gt;예방할 수 있는 방법

&lt;ul&gt;
&lt;li&gt;세컨더리 노드에서 업데이트가 지체되는 상황을 모니터링&lt;/li&gt;
&lt;li&gt;쓰기 연산의 규모에 상응하는 충분한 크기의 오피로그를 가지고 있어야 함&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;오피로그-크기-산정:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;오피로그 크기 산정&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;MongoDB in Action 에서는 오피로그의 크기를 조정할 수 없다고 되어 있으나, v3.0 이후로는 오피로그의 사이즈 조절이 가능함&lt;br /&gt;
※ 참조: &lt;a href=&#34;https://docs.mongodb.com/manual/tutorial/change-oplog-size/&#34;&gt;MongoDB Docs - Change the Size of the Oplog&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;오피로그의 디폴트 크기 &lt;em&gt;(※ 일반적인 경우에는 디폴트 크기로 충분함)&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;3.0 이전&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;32bit 시스템: 50MB&lt;/li&gt;
&lt;li&gt;64bit 시스템: 1GB 또는 사용되지 않는 디스크 공간의 5%&lt;/li&gt;
&lt;li&gt;OS X: 192MB (개발을 위한 시스템으로 고려)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;3.0 이후&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Unix and Windows system

&lt;ul&gt;
&lt;li&gt;In-Memory Storage Engine: 물리 메모리의 5%&lt;/li&gt;
&lt;li&gt;WiredTiger Storage Engine(v3.0 이후로 사용, v3.2 부터는 기본 엔진): 사용되지 않은 디스크 공간의 5%&lt;/li&gt;
&lt;li&gt;MMAPv1 Storage Engine(v3.2 이전의 원래 스토리지 엔진): 사용되지 않은 디스크 공간의 5%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;OS X(64bit)

&lt;ul&gt;
&lt;li&gt;In-Memory Storage Engine: 물리 메모리 192MB&lt;/li&gt;
&lt;li&gt;WiredTiger Storage Engine: 디스크 공간 192MB&lt;/li&gt;
&lt;li&gt;MMAPv1 Storage Engine: 디스크 공간 192MB&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;쓰기가 많이 발생하는 애플리케이션에 대한 오피로그의 결정을 위해서는 경험적 테스트가 필요함&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;복제를 구성하고 프라이머리에서 실제 시스템에서 발생하는 비율로 한 시간 이상 프라이머리에 쓰기를 수행해보고
복제셋에 생성된 현새 상태를 얻어 최소한 8시간은 견딜 수 있는 크기를 추론하여 설정하는 것이 좋음&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;하트비트-heartbeat-와-장애복구:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;하트비트(heartbeat)와 장애복구&lt;/h3&gt;

&lt;p&gt;하트비트(heartbeat)의 역할은 시스템의 건강상태를 모니터링를 통해 장애 복구를 가능하게 하는 것&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MongoDB가 건강상태를 확인하는 방법&lt;/strong&gt;&lt;br /&gt;
- 복제 셋의 각 멤버는 디폴트로 다른 멤버들을 매 2초마다 한 번씩 핑(ping)을 해봄 → 시스템의 건강 상태를 확인할 수 있음
- 상태 명령을 수행했을 때 알 수 있는 정보
  - 상태에 대한 정보(1: 건강, 0: 응답 없음)
  - 각 노드의 마지막 하트비트의 타임스탬프
- 모든 모드가 건강한 상태일 때 만 복제 셋이 정상 동작하는 것이며 한 노드라도 반응이 없으면 조치를 취해야 함&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;장애 발생시 처리 방식&lt;/strong&gt;&lt;br /&gt;
- 세컨더리 노드가 다운
  - 세컨더리의 과반수가 살아있는 경우&lt;br /&gt;
    → 복제 셋은 상태를 변경하지 않고 다운된 세컨더리의 복구를 기다림
  - 세컨더리의 과반수가 살아있지 않은 경우
    - 프라이머리가 세컨더리로 강등
    - WHY?&lt;br /&gt;
      네트워크 장애로 하트비트가 실패한 경우(여전히 온라인 상태) 중재자와 세컨더리가 여전히 살아서 통신 → 프라이머리 선출&lt;br /&gt;
      프라이머리가 2개인 상황이 발생 → 쓰기가 가능한 프라이머리가 2개인 상황이라 데이터의 일관성에 문제 발생
- 프라이머리 노드가 다운
  - 세컨더리의 과반수가 살아있는 경우
    - 세컨더리가 프라이머리로 승격
    - 하나 이상의 세컨더리가 있을 경우에는 가장 최근의 세컨더리가 프라이머리로 승격
  - 세컨더리의 과반수가 살아있지 않은 경우 → &lt;em&gt;System Crush&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;커밋과-롤백:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;커밋과 롤백&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;복제 셋에서 프라이머리의 쓰기가 과반수의 노드에 복제되기 전까지는 커밋되지 않은 것으로 여김&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;롤백&lt;/strong&gt;
&amp;gt; 과반수의 노드에 복제가 되기 전에 세컨더리가 프라이머리로 승격 → 새로운 프라이머리에 쓰기 작업을 수행&lt;br /&gt;
&amp;gt; → 기존 프라이머리 복구 → 새로운 프라이머리로 부터 복제하는 경우
&amp;gt;&lt;br /&gt;
&amp;gt; 예전 프라이머리에는 새로운 프라이머리 노드에는 존재하지 않는 오피로그가 존재할 수 있음 → 롤백 발생&lt;/p&gt;

&lt;p&gt;※ &lt;strong&gt;과반수의 노드에 복제된 적이 없는 쓰기는 모두 취소&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;롤백으로 인해 취소된 데이터는 데이터 경로의 &lt;code&gt;rollback&lt;/code&gt; 이라는 서브디렉토리에 저장됨&lt;br /&gt;
롤백된 데이터를 복구할 필요가 있을 때는 &lt;code&gt;bsondump&lt;/code&gt; 유틸리티로 BSON 파일 검사하고 &lt;code&gt;mongorestore&lt;/code&gt;를 사용해서 복구할 수 있음&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;롤백 상황을 방지하는 방법&lt;/strong&gt;: 쓰기 concern을 사용해서 데이터가 각 쓰기에 대해 과반수의 노드에 복제되는 것이 확실하게 할 수 있음&lt;/p&gt;

&lt;h3 id=&#34;관리:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;관리&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;로컬에서 복제 셋을 만들기 위한 준비&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; $ mongod --replset [name] --dbpath /data/node1 --port 40000
&amp;gt; $ mongod --replset [name] --dbpath /data/node2 --port 40001
&amp;gt; $ mongod --replset [name] --dbpath /data/arbiter --port 40002
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;복제 셋 생성&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; rs.initiate()
&amp;gt; rs.add(&amp;quot;localhost:40001&amp;quot;)
&amp;gt; rs.add(&amp;quot;localhost:40002&amp;quot;, {arbiterOnly: true})
&amp;gt; db.isMaster()
&amp;gt; rs.status()
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;arbiterOnly&lt;/code&gt;: 세컨더리가 짝수일 때 투표에서 중재자 역할을 수행하여 프라이머리 선출에 투표를 함&lt;/li&gt;
&lt;li&gt;&lt;code&gt;db.isMaster()&lt;/code&gt;: 현재 복제 셋의 상태에 대한 간략한 요약을 표시&lt;/li&gt;
&lt;li&gt;&lt;code&gt;db.status()&lt;/code&gt;: 복제 셋 시스템에 대한 자세한 상태 정보를 표시&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;오피로그에 대한 기본 정보 확인&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;  &amp;gt; db.getReplicationInfo()
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;오피로그의 크기를 설정&lt;/strong&gt; (크기는 MB 단위)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;  $ mongod --replSet myapp --oplogSize 1024
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;복제 셋의 생성을 설정 도큐먼트를 이용해서 수행&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; config = {_id: &amp;quot;myapp&amp;quot;, members:[]}
&amp;gt; config.members.push({_id: 1, host: &amp;quot;localhost:40001&amp;quot;})
&amp;gt; config.members.push({_id: 0, host: &amp;quot;localhost:40000&amp;quot;})
&amp;gt; config.members.push({_id: 2, host: &amp;quot;localhost:40002&amp;quot;, arbiterOnly: true})
&amp;gt; config
{
  &amp;quot;_id&amp;quot;: &amp;quot;myapp&amp;quot;,
  &amp;quot;members&amp;quot;: [
    {
      &amp;quot;_id&amp;quot;: 0,
      &amp;quot;host&amp;quot;: &amp;quot;localhost:40000&amp;quot;
    },
    {
      &amp;quot;_id&amp;quot;: 1,
      &amp;quot;host&amp;quot;: &amp;quot;localhost:40001&amp;quot;
    },
    {
      &amp;quot;_id&amp;quot;: 2,
      &amp;quot;host&amp;quot;: &amp;quot;localhost:40002&amp;quot;,
      &amp;quot;arbiterOnly&amp;quot;: true
    }
  ]
}
&amp;gt; rs.initiate(config)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;설정-도큐먼트-옵션:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;설정 도큐먼트 옵션&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;복제 셋 개별 멤버에 대한 설정 옵션

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;_id&lt;/code&gt;(필수): 멤버의 아읻를 나타내는 고유한 정수 값 (0부터 시작해서 1씩 증가)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host&lt;/code&gt;(필수): 호스트 이름과 포트&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arbiterOnly&lt;/code&gt;:  중재자인지 여부를 설정&lt;br /&gt;
&lt;strong&gt;Arbitor&lt;/strong&gt;: 프라이머리 선정에만 참여하고 복제하지 않는 경량 멤버&lt;/li&gt;
&lt;li&gt;&lt;code&gt;priority&lt;/code&gt;: 장애 발생시 프라이머리로 선출될 가능성(0~1000), 0으로 설정할 경우 프라이머리로 선정되지 않음&lt;/li&gt;
&lt;li&gt;&lt;code&gt;votes&lt;/code&gt;: 프라이머리 선출시의 표 수를 지정(모든 복제 멤버들은 디폴드로 한 표를 받음)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hidden&lt;/code&gt;: &lt;code&gt;isMaster()&lt;/code&gt;에 의해 생성되는 응답에서 숨김 → 애플리케이션(드라이버)에서 접속하는 것을 막을 수 있음&lt;/li&gt;
&lt;li&gt;&lt;code&gt;buildIndexes&lt;/code&gt;: 인덱스를 구축할 지 여부를 설정(기본 값: &lt;code&gt;true&lt;/code&gt;)&lt;br /&gt;
프라이머리가 되지 않을 멤버에 대해서만 설정해야 함(&lt;code&gt;priority: 0&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;slaveDelay&lt;/code&gt;: 세컨더리가 프라이머리 변경을 적용하는데 걸리는 지연 시간을 초 단위로 설정&lt;br /&gt;
프라이머리가 되지 않을 멤버에 대해서만 설정해야 함(&lt;code&gt;priority: 0&lt;/code&gt;)&lt;br /&gt;
데이터베이스의 의도되지 않은 문제 발생(예: 실수에 의한 프라이머리 삭제)에 대응(복구)하기 위해 활용할 수 있음&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tags&lt;/code&gt;: 임의의 키-값 쌍인 도큐먼트, 데이터센터나 랙에서의 위치등을 설명하기 위해 사용할 수 있음&lt;br /&gt;
쓰기 concern과 읽기 세팅을 지정하는데 사용될 수 있음&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;settings&lt;/code&gt;(글로벌 복제 셋 설정)의 옵션

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;getLastErrorDefaults&lt;/code&gt;: 클라이언트가 파라미터 없이 &lt;code&gt;getLastError&lt;/code&gt;를 호출할 때 사용되는 기본 매개변수 설정&lt;/li&gt;
&lt;li&gt;&lt;code&gt;getLastErrorModes&lt;/code&gt;: &lt;code&gt;getLastError&lt;/code&gt; 명령에 대한 추가적인 모드를 정의&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;복제-셋-상태:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;복제 셋 상태&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; rs.status()
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;상태&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;상태 문자열&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;설명&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;STARTUP&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;복제 셋이 모든 복제 셋 멤버를 핑하고 설정 데이터를 공유함으로써 다른 노드와 교섭 중&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;PRIMARY&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;프라이머리 노드&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;SECONDARY&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;세컨더리 읽기 전용 노드&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;RECOVERING&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;읽기/쓰기를 진해할 수 없음, 장애 복구 후 또는 노드 추가 시 볼수 있음&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;FATAL&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;네트워크가 연결되었으나 노드가 반응하지 않음, 해당 노드의 호스트 서버에 오류가 있을 경우&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;STARTUP2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;초기 데이터 파일 동기화가 진행 중&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;UNKNOWN&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;네트워크 연결이 이루어져야 함&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;ARBITER&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;노드가 중재자 임&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;DOWN&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;이 노드가 액세스 가능하고 어느 시점에서는 안정적이지만 현재 하트비트 핑에 응답하지 않음&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;ROLLBACK&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;롤백이 수행되고 있음&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;장애조치와-복구:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;장애조치와 복구&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;장애 발생 시 새로운 프라이머리를 선출하기 위해서는 과반수 이상이 필요하고,&lt;br /&gt;
프라이머리는 자신이 과반수 이상에 머물러 있는 한 프라이머리로서의 역할을 유지할 수 있음&lt;br /&gt;
과반수 이상이 복제되면 쓰기가 안전해짐&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;과반수&lt;/strong&gt;: 복제 셋의 모든 멤버의 절반보다 많은 것&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;복제 셋의 멤버 수에 따른 과반수의 예&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;복제 셋의 멤버 수&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;복제 셋의 과반수&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;※ &lt;strong&gt;중재자(arbitor)의 역할&lt;/strong&gt;&lt;br /&gt;
  프라이머리 1대와 세컨더리 1대로 이뤄진 복제 셋의 과반수는 2인데 프라이머리의 장애시 투표를 행사할 수 있는
  서버는 1대 뿐이므로 프라이머리를 선출할 수 없다.&lt;br /&gt;
  그러므로, 데이터의 복제에는 참여하지 않지만 프라이머리 선출에만 참여하는 중재자가 필요하다.&lt;/p&gt;

&lt;h4 id=&#34;장애-모드:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;장애 모드&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;깨끗한 장애(clean failure)&lt;/strong&gt;: 주어진 노드의 데이터 파일이 아직 손상되지 않은 상태

&lt;ul&gt;
&lt;li&gt;발생 케이스: 네트워크 장애, mongodb 프로세스의 종료&lt;/li&gt;
&lt;li&gt;복구 방식: 네트위크 복귀, 프로세스의 재시작&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;확실한 장애(categorical failure)&lt;/strong&gt;: 주어진 노드의 데이터 파일이 더 이상 존재하지 않거나 데이터 파일이 깨진 상태&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;발생 케이스: mongod 프로세스가 저널링이 사용되지 않은 상태에서 불시에 셧다운된 경우, 하드 디스크가 깨진 경우&lt;/li&gt;
&lt;li&gt;복구 방식: 재동기화를 통한 데이터 파일을 완전 대치, 최근 백업에서 복구&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;rs-reconfigure-를-이용한-복제-셋-재설정:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;&lt;code&gt;rs.reconfigure()&lt;/code&gt;를 이용한 복제 셋 재설정&lt;/h4&gt;

&lt;p&gt;복구가 불가능한 노드(&lt;code&gt;localhost:30001&lt;/code&gt;)를 새로운 노드(&lt;code&gt;localhost:40001&lt;/code&gt;)를 만들어서 대체하는 경우&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; use local
&amp;gt; config = db.system.replset.findOne()
{
  &amp;quot;_id&amp;quot;: &amp;quot;myapp&amp;quot;,
  &amp;quot;version&amp;quot;: 1,
  &amp;quot;members&amp;quot;: [
    {
      &amp;quot;_id&amp;quot;: 0,
      &amp;quot;host&amp;quot;: &amp;quot;localhost:30000&amp;quot;
    },
    {
      &amp;quot;_id&amp;quot;: 1,
      &amp;quot;host&amp;quot;: &amp;quot;localhost:30001&amp;quot;
    },
    {
      &amp;quot;_id&amp;quot;: 2,
      &amp;quot;host&amp;quot;: &amp;quot;localhost:30002&amp;quot;,
      &amp;quot;arbiterOnly&amp;quot;: true
    }
  ]
}
&amp;gt; config.members[1].host = &amp;quot;localhost:40001&amp;quot;
&amp;gt; config.reconfigure(config)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;→ 복제 셋은 새 노드를 인식하고 새 노드는 기존 멤버로 부터 동기화를 시작함&lt;/p&gt;

&lt;h4 id=&#34;백업으로-부터-복구:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;백업으로 부터 복구&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;백업에 의한 복구는 백업 내의 오피로그가 현재 복제셋의 오피로그와 비교해서 같은 경우에만 사용할 수 있음&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;백업 오피로그의 최근 연산이 현재 복제 셋의 오피로그에 여전히 존재해야 함 → &lt;code&gt;db.getReplicationInfo()&lt;/code&gt;가 제공하는 정보로 확인할 수 있음&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;백업의 오피로그 항목이 백업이 복구되는 시점에서 오래 되었다면 재동기를 수행하는 것이 효율적일 수 있음&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;백업 데이터 파일을 mongod 데이터 경로로 복사 → 동기화는 자동 시작 → &lt;code&gt;rs.status()&lt;/code&gt;로 확인 가능

&lt;ul&gt;
&lt;li&gt;인덱스를 재구축할 필요가 없으므로 대부분의 경우 빠르게 복구가 가능하다&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;배포-전략:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;배포 전략&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;복제 셋의 최대 갯수: 12&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;자동-장애-조치를-제공할-수-있는-최소-구성:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;자동 장애 조치를 제공할 수 있는 최소 구성&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;2개의 복제 노드 + 1개의 중재자&lt;/li&gt;
&lt;li&gt;중재자(arbiter)는 애플리케이션 서버에 존재 + 복제 노드는 개별 서버를 구성&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;업타임이-중요한-서비스의-구성:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;업타임이 중요한 서비스의 구성&lt;/h4&gt;

&lt;p&gt;3개의 완전한 복제 노드로 구성&lt;br /&gt;
→ 한 노드가 완전히 기능 정지힌 경우에도 2개의 노드는 정상 동작하며 복구 중에도 자동 장애조치를 처리할 수 있음&lt;/p&gt;

&lt;h4 id=&#34;2개의-데이터-센터로-구성:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;2개의 데이터 센터로 구성&lt;/h4&gt;

&lt;p&gt;두 데이터 센터 중 하나는 재해 복구 목적(세컨더리 데이터 센터)으로만 사용하는 경우
※ 복제 셋의 프라이머리는 항상 프라이머리 데이터 센터에 존재하도록 설정
* &lt;strong&gt;프라이머리 데이터 센터&lt;/strong&gt;: 프라이머리(1) + 세컨더리(1)
* &lt;strong&gt;세컨더리 데이터 센터&lt;/strong&gt;: 세컨더리(1: priority=0)
* 프라이머리 데이터 센터 내의 노드들 모두를 사용할 수 없을 경우
  * 세컨더리 데이터 센터의 세컨더리 노드를 임시로 사용: mongodb 서버의 셧다운 → &lt;code&gt;--replSet&lt;/code&gt; 옵션 없이 재시작
  * 세컨더리 데이터 센터에 노드 2개를 생성 → 복제 셋의 재설정을 강제적으로 수행 (&lt;code&gt;force&lt;/code&gt;옵션 사용)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; rs.reconfigure(config, {force: true})
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;드라이버와-복제:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;드라이버와 복제&lt;/h2&gt;

&lt;p&gt;복제 셋을 사용하는 어플리케이션 개발시 고려 주제
* 연결과 장애조치
* 쓰기 concern
* 읽기 확장&lt;/p&gt;

&lt;h3 id=&#34;연결과-장애-조치:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;연결과 장애 조치&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;드라이버는 MongoDB에 접속하면 &lt;code&gt;isMaster&lt;/code&gt; 명령을 수행&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;단일-노드-연결:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;단일 노드 연결&lt;/h4&gt;

&lt;p&gt;복제 셋의 마스터로 지정된 노드에 연결하는 것 (독립 MongoDB 노드로 접속하는 것과 동일)
※ 만일 세컨더리 노드에 접속하려면 세컨더리 노드에 접속하고 있음을 명기해야만 한다.&lt;/p&gt;

&lt;h4 id=&#34;복제-셋-연결:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;복제 셋 연결&lt;/h4&gt;

&lt;p&gt;복제 셋을 하나의 전체로 보고 연결&lt;br /&gt;
→ 드라이버는 어떤 노드가 프라이머리인지 파악하고 장애조치의 경우에 새로운 프라이머리가 된 노드에 재연결&lt;/p&gt;

&lt;h3 id=&#34;쓰기-concern:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;쓰기 concern&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;개발자로 하여금 애플리케이션이 진행되기 전에 쓰기가 어느정도로 복재되어야 하는지를 지정하는 것&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;getlasterror&lt;/code&gt; 명령에 대해 &lt;code&gt;w&lt;/code&gt;와 &lt;code&gt;wtimeout&lt;/code&gt; 필드를 통해 조정됨
- &lt;code&gt;w&lt;/code&gt;: 쓰기 연산을 복제할 서버의 수&lt;br /&gt;
  - 쓰기가 최소한 하나의 서버에 복제되어야 한다면 &lt;code&gt;w&lt;/code&gt;를 &lt;code&gt;2&lt;/code&gt;로 설정&lt;br /&gt;
  - &lt;code&gt;w&lt;/code&gt; 값이 1보다 큰 쓰기 concern을 사용할 경우 추가적인 지연이 발생한다는 점을 명심해야 함&lt;br /&gt;
  - 저널링을 사용하는 경우 &lt;code&gt;w&lt;/code&gt;를 &lt;code&gt;1&lt;/code&gt;로 정하는 것이 대부분의 애플리케이션에서 효율적임
- &lt;code&gt;wtimeout&lt;/code&gt;: 쓰기가 지정된 시간 내에 복제되지 못할 경우 에러를 리턴하도록 하는 타임아웃 시간 (단위: 밀리초)
  ※ &lt;code&gt;wtimeout&lt;/code&gt;을 설정하지 않은 상태에서 복제가 발생하지 않으면 해당 연산은 무한 블록됨&lt;/p&gt;

&lt;h3 id=&#34;읽기-스케일링:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;읽기 스케일링&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;복제 셋은 쓰기는 프라이머리에만 가능하지만 읽기는 세컨더리에도 가능하므로 읽기 부하를 분산을 시킬 수 있다.
각 드라이버들은 쿼리를 하나 이상의 세컨더리 노드로 보내는 옵션을 제공하고 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;※ 자바에서 &lt;code&gt;slaveOk&lt;/code&gt; 옵션을 &lt;code&gt;true&lt;/code&gt;로 지정하면 스레드당 로드 밸런싱을 사용&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;읽기 스케일링을 자제 해야할 경우

&lt;ul&gt;
&lt;li&gt;애플리케이션의 쓰기 부하가 많을 경우&lt;br /&gt;
쓰기 연산을 빈번하게 수행하는 세컨더리에 읽기 요청을 보내는 것은 원활한 복제를 가로막을 수 있음&lt;/li&gt;
&lt;li&gt;일관성이 요구되는 읽기를 해야할 경우&lt;br /&gt;
복제는 비동기적이므로 최근에 프라이머리에 수행된 쓰기가 반영하지 않았을 수도 있음&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;태깅:177f2075b6e19d6ba296a382cdb81d27&#34;&gt;태깅&lt;/h3&gt;

&lt;p&gt;쓰기 concern 이나 읽기 확장을 사용하고 있을 경우 사용할 세컨더리 노드를 세밀하게 제어하기 위해 사용할 수 있다.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>인덱싱과 쿼리 최적화</title>
      <link>http://kwsstudy.github.io/post/%EC%9D%B8%EB%8D%B1%EC%8B%B1%EA%B3%BC-%EC%BF%BC%EB%A6%AC-%EC%B5%9C%EC%A0%81%ED%99%94/</link>
      <pubDate>Sun, 27 Nov 2016 12:00:00 +0900</pubDate>
      
      <guid>http://kwsstudy.github.io/post/%EC%9D%B8%EB%8D%B1%EC%8B%B1%EA%B3%BC-%EC%BF%BC%EB%A6%AC-%EC%B5%9C%EC%A0%81%ED%99%94/</guid>
      <description>

&lt;h2 id=&#34;인덱싱과-쿼리-최적화:4b17b39bee401b784b526ec221a2040f&#34;&gt;인덱싱과 쿼리 최적화&lt;/h2&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;인덱싱의-이론적-고찰:4b17b39bee401b784b526ec221a2040f&#34;&gt;인덱싱의 이론적 고찰&lt;/h2&gt;

&lt;h3 id=&#34;개념실험:4b17b39bee401b784b526ec221a2040f&#34;&gt;개념실험&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;두꺼운 요리책이 있다. 이 책은 5000장으로 이루어져 있으며 요리법에는 특별한 순서가 없다. 3,475페이지에는 호주의 오리 찜 요리가 있으며, 2페이지에는 자카테칸 타코가 있다. 인덱스가 없이 요리책에서 로즈메리 감자 요리법을 찾을 수 있을까? 유일한 방법은 그 요리법이 나올 때까지 처음부터 훑어 나가는 것이다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;이에 대한 해결책이 인덱스를 생성하는 것이다.. 요리법을 찾기 위해서는 여러 가지 방법을 생각해 낼 수 있지만 가장 좋은 방법은 요리법의 이름으로 찾는 것이다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;티벳 야크 수페:45&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;구운 소금 덤플링 : 4,011&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;터키 알 라 킹 : 943&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;만약 다른 기준으로 요리법을 찾기 위해서는 또 다른 인덱스가 필요하다. 만약 재료에 대한 인덱스를 만들게 된다면
캣슈: 3, 20, 42, 88&amp;hellip;
콜리플라워: 2, 47, 89&amp;hellip;
닭: 7, 9, 1111, 2222&amp;hellip;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;이 인덱스는 유용할까? 요리법에 관한 어떤 다른 정보를 찾고 있다면 여전히 이 인덱스는 개선의 여지가 있다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;예) 몇 개월 전 요리책에서 닭 요리법을 우연히 보았는데 이 요리법을 잊었다. 현재, 요리법에서 이름과, 재료에 대한 인덱스 2개가 있을 경우 닭 요리를 발견할 수 있는 방법은?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;사실 이것은 불가능하다. 재료에 대한 인덱스로 시작한다면 확인해볼 수 있는 페이지 번호의 리스트는 있지만 이 페이지 번호를 요리법 이름에 대한 인덱스와 연결할 수 있는 방법이 전혀 없다. 따라서 이 경우에 어느 하나의 인덱스만 사용할 수밖에 없고, 두 인덱스 중에서 재료에 대한 인덱스가 더 유용하다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;ul&gt;
&lt;li&gt;쿼리당 하나의 인덱스 : 두 필드에 대해 검색할 때 2개의 인덱스를 별도로 만들 경우 알고리즘은 이렇다. 각각의 인덱스에서 검색어와 일치하는 페이지를 찾고 이 페이지 번호를 합친 리스트를 스캔하면서 두 검색어와 일치하는 요리법을 찾는다. 하지만 MongoDB는 그렇지 않다. MOngoDB는 복합 인덱스를 사용한다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;복합인덱스 : 하나 이상의 키를 사용하는 인덱스(책 179p참조)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;복합인덱스는 순서가 중요하다. 재료-이름 인덱스를 생성했다고 가정하면, 재료부터 찾고 해당 재료인덱스에 있는 이름을 찾기 때문이다. 이 복합 인덱스가 존재하면 재료에 대한 단일 키 인덱스는 삭제해도 문제가 없다. 재료로 검색 할 때 재료-이름의 복합 인덱스를 사용하면 되기 때문이다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;이 장의 목적은 비유를 통해 인덱스를 개념적으로 설명하자는 것이다. 이 비유로부터 다음과 같은 일반적인 규칙 몇 가지를 도출 할 수 있다.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;인덱스는 도큐먼트를 가져오기 위해 필요한 작업량을 많이 줄인다. 적당한 인덱스가 없으면 질의 조건을 만족할 때까지 모든 도큐먼트를 차례로 스캔해야만 하고, 이것은 종종 컬렉션 전체를 스캔하는 것을 의미한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;한 쿼리를 실행하기 위해서 하나의 단일 키 인덱스만 사용할 수 있다. 복합 키를 사용하는 쿼리에 대해서는 복합 인덱스가 적합하다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;재료-지역 요리에 대한 인덱스를 가지고 있다면 재료에 대한 인덱스는 없앨 수 있고 또 없애야만 한다. 좀 더 일반적으로 표현하자면, a-b에 대한 복합 인덱스를 가지고 있다면 a에 대한 인덱스는 중복이다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;복합 인덱스에서 키의 순서는 매우 중요하다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;인덱싱-핵심-개념:4b17b39bee401b784b526ec221a2040f&#34;&gt;인덱싱 핵심 개념&lt;/h2&gt;

&lt;h3 id=&#34;단일-키-인덱스:4b17b39bee401b784b526ec221a2040f&#34;&gt;단일 키 인덱스&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;단일 키 인덱스에서 인덱스 내의 각 엔트리는 인덱스되는 도큐먼트 내의 한 값과 일치한다. _id에 대해 디폴트로 생성되는 인덱스가 좋은 예인데, 각 도큐먼트의 _id는 빠른 검색을 위해 인덱스에 저장된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;복합키-인덱스:4b17b39bee401b784b526ec221a2040f&#34;&gt;복합키 인덱스&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;MongoDB는 쿼리당 하나의 인덱스만 사용한다. products 컬렉션에 대해 2개의 인덱스를 생성한다고 가정한다.
한 인덱스는 제조사에 대한 것이고 다른 하나는 가격에 대한 인덱스이다. 이것은 완전히 다른 2개의 데이터 구조를 생성했다는 것을 의미하고 아래와 같이 저렬이 되어 있다.
&lt;table&gt;
&lt;tr&gt;&lt;td&gt;Ace&lt;/td&gt;&lt;td&gt;Ox12&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Acme&lt;/td&gt;&lt;td&gt;OxFF&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Acme&lt;/td&gt;&lt;td&gt;OxA1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Acme&lt;/td&gt;&lt;td&gt;Ox0B&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Acme&lt;/td&gt;&lt;td&gt;Ox1C&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Biz&lt;/td&gt;&lt;td&gt;OxEE&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;tr&gt;&lt;td&gt;7999&lt;/td&gt;&lt;td&gt;OxFF&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;7500&lt;/td&gt;&lt;td&gt;Ox12&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;7500&lt;/td&gt;&lt;td&gt;OxEE&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;7500&lt;/td&gt;&lt;td&gt;OxA1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;7499&lt;/td&gt;&lt;td&gt;Ox0B&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;7499&lt;/td&gt;&lt;td&gt;Ox1C&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.find({&#39;details.manufacturer&#39;:&#39;Acme&#39;, &#39;pricing.sale&#39; : {$lt:7500}})
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;위의 쿼리는 제조사가 Acme고 가격이 700보다 싼 것을 의미하는데 단일 키 인덱스에 대해 실행하면 2개의 인덱스 가운데 하나만 사용된다. 쿼리 옵티마이저는 두 인덱스 중에서 가장 효율적인 인덱스를 선택하지만 어떤 것도 좋은 결과를 가져다 주진 않는다. 이 인덱스를 사용하는 쿼리를 만족시키기 위해서는 각 인덱스를 따로 탐색해서 일치하는 디스크 위치의 리스트를 합쳐서 유니온을 계산해야 하지만 MongoDB는 이런 방식을 지원하지 않는다. 여러 가지 이유 중 하나는 복합 인덱스를 사용하는 것이 좀 더 효율적이기 때문이다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;복합키를 생성하면 다음과 같은 순서를 같게된다.
&lt;table&gt;
&lt;tr&gt;&lt;td&gt;Ace - 8000&lt;/td&gt;&lt;td&gt;OxFF&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Acme - 7999&lt;/td&gt;&lt;td&gt;Ox12&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Acme - 7500&lt;/td&gt;&lt;td&gt;OxEE&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Acme - 7499&lt;/td&gt;&lt;td&gt;OxA1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Acme - 7499&lt;/td&gt;&lt;td&gt;Ox0B&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Biz - 8999&lt;/td&gt;&lt;td&gt;Ox1C&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
쿼리를 수행하기 위해 쿼리 옵티마이저는 인덱스 내에서 제조사가 &amp;lsquo;Acme&amp;rsquo;이고 가격이 75불인 첫 번째 엔트리를 찾아야 한다. 그 엔트리부터 시작해서 제조사 값이 Acme가 아닌 엔트리를 발견할 때까지 인덱스 내의 엔트리를 스캔 함으로써 결과를 얻을 수 있다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;인덱스-효율:4b17b39bee401b784b526ec221a2040f&#34;&gt;인덱스 효율&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;쿼리 성능을 위해서는 인덱스가 반드시 필요하지만 각 인덱스는 유지 비용이 들어간다. 왜 그런지는 쉽게 이해할 수 있다. 어떤 컬렉션에 도큐먼트를 추가할 때마다 그 컬렉션에 대해 생성된 인덱스도 그 새로운 도큐먼트를 포함시키도록 수정해야 한다. 따라서 어떤 컬렉션이 10개의 인덱스를 가지고 있다면, 삽입 연산을 한 번 수행할 때마다 10개의 인덱스를 수정해야 한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;읽기 위주의 애플리케이션에서 인덱스 비용은 인덱스로 인해 얻을 수 있는 효과로 상쇄된다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;인덱스가 적합하게 만들어졌다고 해도 쿼리를 더 빠르게 처리하지 못할 가능성이 여전히 존재한다는 점이다. 이것은 인덱스와 현재 작업 중인 데이터를 램에서 다 처리하지 못할 때 발생한다. MongoDB는 운영체제에게 mmap() 시스템 호출을 이용해 모든 데이터 파일을 메모리에 매핑하는ㄷ, 이 시점부터는 모든 도큐먼트, 컬렉션, 인덱스를 포함하는 데이터 파일이 페이지라고(page)라고 부르는 4KB의 청크로 운영체제에 의해 램으로 스왑된다. 해당 페이지에 대한 데이터가 요청 될 때마다 OS는 그 페이지가 램에 있는지 확인해야 한다. 만약 램에 없으면 페이지 폴트(page fault) 예외를 발생 시키고 메모리 관리자는 해당 페이지를 디스크로부터 램으로 불러들인다. 램이 충분하면 모든 데이터 파일이 램으로 로드가 된다. 모든 데이터를 램이 수용하지 못하는 경우 점점 페이지 폴트가 발생하고 모든 읽기와 쓰기에 대해서 디스크 액세스를 해야 하는 상환이 발생할 수도 있다. 이러한 현상을 스래싱(thrashing)이라고 하는데, 성능을 심각하게 저해한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;이상적으로는 인덱스와 현재 작업 중인 데이터가 모두 램에 존재해야 한다. 하지만 램의 필요한 크기를 추정하는 것이 항상 쉬운 것만은 아니다. 작업 데이터는 애플리케이션마다 다르기 때문에 어느 정도의 크기를 갖는지 명확히 알기가 어렵기 때문이다. 하드웨어와 관련된 성능 문제를 진단하기 위한 몇가지 구체적인 방법은 10장에 나온다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;b트리:4b17b39bee401b784b526ec221a2040f&#34;&gt;B트리&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;MongoDB는 내부적으로 B트리(B-tree)로 인덱스를 생성한다. B트리는 데이터 베이스 인덱스에 이상적인 두 가지의 전반적인 특성을 가지고 있다. 첫 번째로 정확한 일치, 범위 조건, 정렬, 프리픽스 일치, 인덱스만의 쿼리 등 다양한 쿼리를 용이하게 처리하도록 해준다는 점이다. 두 번째로는 키가 추가되거나 삭제되더라도 밸런스된 상태를 계속 유지한다는 점이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://ko.wikipedia.org/wiki/B_%ED%8A%B8%EB%A6%AC&#34;&gt;B트리 위키&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;인덱싱의-실제:4b17b39bee401b784b526ec221a2040f&#34;&gt;인덱싱의 실제&lt;/h2&gt;

&lt;h3 id=&#34;인덱스-타입:4b17b39bee401b784b526ec221a2040f&#34;&gt;인덱스 타입&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;고유 인덱스
고유 인덱스를 생성하기 위해서는 unique옵션을 지정한다&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.users.ensureIndex({username:1},{unique:true})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;고유 인덱스는 컬렉션에 데이터가 존재하지 않을 때 생성하는 것이 좋다. 데이터가 있는 경우 고유 인덱스를 만들면, 컬렉션 내에서 중복 키가 존재할 가능성이 있기 때문이다. 하지만 데이터가 그다지 중요하지 않다면 데이터 베이스로 하여금 dropDups옵션을 이용해 중복 키를 가지고 있는 도큐먼트를 자동으로 삭제하도록 명령을 내릴 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.users.ensureIndex({username:1},{unique:true, dropDups:true})
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;희소 인덱스
인덱스는 밀집(dense)하도록 기본 설정되어 있다. 밀집 인덱스란 컬렉션 내의 한 도큐먼트가 인덱스 키를 가지고 있지 않더라도 인덱스에는 해당 엔트리가 존재한다는 것을 의미한다. 하지만 밀집 인덱스가 바람직하지 않은 경우가 있다. 첫 번째는 모든 도큐먼트의 sku필드에 대해 고유 인덱스를 만든다고 가정하자. 하지만 sku필드에 대해 입력없이 등록할 수 있는 시스템이 있다. sku입력없이 여러개의 도큐먼트를 삽입하려고 할 때 sku가 null인 인덱스가 이미 존재하기 때문에 이 후 에러가 발생 할 수 있다. 이런 경우에 희소 인덱스(sparse index)가 필요하다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.users.ensureIndex({sku:1},{unique:true, sparse:true})
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;다중 키 인덱스
필드의 값이 배열인 경우 인덱스하는 것이 다중 키 인덱스인데, 인덱스 내의 여러 개의 엔트리가 동일한 도큐먼트를 지시하게 된다.
아래와 같은 형태의 도큐먼트들이 있다고 가정하자.
&lt;code&gt;javascript
{name:&amp;quot;Wheelbarrow&amp;quot;,
tags: [&amp;quot;tools&amp;quot;, &amp;quot;gardening&amp;quot;, &amp;quot;soil&amp;quot;]
}
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;tags에 대해 인덱스를 생성하면 이 도큐먼트의 태그 배열에 있는 각 값들은 인덱스에 나타한다. 이것은 이 배열의 값 중 어느 것으로도 도큐먼트를 찾을 수 있음을 의미한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;인덱스-관리:4b17b39bee401b784b526ec221a2040f&#34;&gt;인덱스 관리&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;인덱스 생성과 삭제
일반적으로 인덱스를 생성하는데 헬퍼 메소드를 사용하는 것이 쉽지만 인덱스 규격을 직접 삽입(인덱스 헬퍼 메소드가 하는일)할 수도 있는데
ns, key, name이렇게 최소한의 키를 지정하기만 하면 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;spec = {ns:&amp;quot;green.users&amp;quot;, key:{&#39;addresses.zip&#39;:1}, name:&#39;zip&#39;}
db.system.indexes.insert(spec, true)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;인덱스를 삭제하기 위해서 system.indexes에서 인덱스 도큐먼트를 삭제하면 될 것이라고 생각할지도 모르지만 이런 연산은 금지되어 있으며 deleteIndexes를 수행해서 인덱스를 삭제하면 된다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;**책에서는 인덱스 조회시 db.system.indexes를 사용하는데 현재 이 방법을 사용할 경우 오류는 나지 않지만 결과가 없다
검색을 해 보니 db.users.getIndexes() 함수가 존재했다.. 위의 방식으로 인덱스가 생성은 되나 검색결과 createIndex와 같은 함수로 인덱스를 생성할 수 있는 것으로 보아 버전업이 되면서 책과 차이가 좀 있는 것으로 보인다. **&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;인덱스 선언 시 주의사항
인덱스를 선언하는 것이 너무 쉽기 때문에 의도치 않게 인덱스를 구축하는 것도 역시 아주 쉽다. 데이터가 대량일 경우 인덱스 구축은 오랜 시간이 걸린다. 실제 서비스 상황에서는 이것은 악몽과도 같다. 왜냐하면 인덱스 구축을 중지시키기가 쉽지 않기 때문이다. 만일 이런 일이 발생한다면, 세컨더리 노드가 있는 경우 이 노드로 서비스를 해야 할 것이다. 하지만 인덱스 구축을 일종의 데이터베이스 마이그레이션으로 취급하고 애플리케이션에서 인덱스 선언이 자동으로 되지 않도록 하는 것이 현명하다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;백그라운드 인덱싱
데이터베이스가 실제 서비스되고 있고 데이터베이스에 대한 액세스를 중지시킬 수 없을 경우 사용하는 방법. 어플리케이션의 트래픽이 최소화되는 시간 내에 인덱스를 구축할 수 있다면 좋은 방법이 될 수 있다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;오프라인 인덱싱
실제 서비스되괴 있는 데이터가 인덱스를 생성하는데 몇 시간으로는 부족할 정도로 큰 규모라면 다른 방법이 필요하다. 일반적으로 한 복제 노드를 오프라인 상태로 바꾸고, 그 노드에 대해 인덱스를 구축한 다음에 마스터 노드로부터 업데이트를 받는다. 업데이트를 완료하고 나면 이 노드를 프라이머리 노드로 변경하고, 다른 센컨더리 노드들은 오프라인 상태로 바꾼 후에 각자 인덱스를 구축한다. 이것은 오프라인 노드에서 인덱스를 구축하는 동안 데이터가 손상되는 것을 막을 정도로 복제 oplog가 충분히 크다는 가정을 전제로 한다. 이에 대해서는 다음장에서 자세히 다룬다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;백업
인덱스는 구축하기 어렵기 때문에 백업을 해놓아야 한다. 백업이 인덱스를 포함하길 원한다면 MongoDB의 데이터 파일 자체를 백업해야 한다. 자세한 내용과 일반적인 백업 명령은 10장에서 다룬다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;압축
어플리케이션에서 기존 데이터의 업데이트나 대량의 데이터 삭제가 자주 발생한다면 인덱스가 심각하게 단편화된다. B트리는 어느 정도 스스로 재구성하지만 대량의 삭제를 상쇄시킬 만큼 충분치는 않다. 단편화된 인덱스의 일차적인 징후는 주어진 데이터의 크기보다 인덱스의 크기가 훨씬 더 큰 것이고, 이로인해 인덱스가 램을 필요이상으로 많이 사용할 수 있다. 이런 경우에 하나 혹은 그 이상의 인덱스를 재구축하는 것을 고려해야 한다. 이 때 reIndex()명령을 수행하여 개별 인덱스를 삭제하고 재생성함으로써 가능하다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;쿼리-최적화:4b17b39bee401b784b526ec221a2040f&#34;&gt;쿼리 최적화&lt;/h2&gt;

&lt;p&gt;쿼리 최적화는 느린 쿼리를 찾아서 원인을 발견하고, 속도를 개선하기 위한 조치를 취하는 과정이다. 애플리케이션의 잘못된 설계, 적합하지 않은 데이터 모델, 부족한 하드웨어는 모두 공통적인 원인이고, 이런 문제점을 해결하기 위해서는 많은 시간이 요구된다. 이 장에서는 쿼리를 재구성하고 좀 더 유용한 인덱스를 구축함으로써 쿼리를 최적화하는 방안을 살펴본다.&lt;/p&gt;

&lt;h3 id=&#34;느린-쿼리-탐지:4b17b39bee401b784b526ec221a2040f&#34;&gt;느린 쿼리 탐지&lt;/h3&gt;

&lt;p&gt;요구사항이 애플리케이션마다 다르지만, 대부분 애플리케이션에서 쿼리가 100밀리초 이내에 실행되어야 한다고 가정하면 안전하다. MongoDB 로거는 이 가정에 근거, 질의를 포함해서 어떠한 연산이라도 100밀리초를 넘어서면 경고 메시지를 프린트한다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://mng.bz/ii49&#34;&gt;http://mng.bz/ii49&lt;/a&gt;
위의 더미 데이터는 400만건 이상의 데이터가 있다..&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.values.find({&amp;quot;stock_symbol&amp;quot;:&amp;quot;GOOG&amp;quot;}).sort({data:-1}).limit(1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이 쿼리를 수행한 결과 2.332sec가 나왔다. 상당히 느린 것이다.&lt;/p&gt;

&lt;p&gt;느린 쿼리를 확인하기 위해서 MongoDB의 로그를 사용할 수 있지만, 이러한 절차가 정교하지 못하기 때문에 개발이나 서비스 환경에서 시도해볼 수 있는 일종의 점검 장치로 생각해야한다. 문제가 발생하기 전에 느린 쿼리를 찾기 위해서는 정확한 툴이 필요한데, MongoDB에 내장된 쿼리 프로파일러가 바로 그것이다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;프로파일러 사용
프로파일링은 디폴트로 사용 불가능 상태이므로 사용 가능 상태로 바꾸자
&lt;code&gt;javascript
use stocks
db.setProfilingLevel(2)
&lt;/code&gt;
먼저 프로파일하려는 데이터베이스를 선택해야 한다. 프로파일링은 항상 특정 데이터베이스에 국한된다. 프로파일링 수준을 2는 출력이 가장 많이 되는 수준인데, 프로파일러가 모든 읽기와 쓰기를 로그에 기록한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;프로파일링 결과는 system.profile이라고 부르는 특수한 캡드(capped)컬렉션에 저장된다. 캡드 컬렉션은 크기가 고정되어 있고 데이터는 회전되는 방식으로 쓰여지기 때문에 컬렉션이 허용된 크기에 도달하면 새로운 도큐먼트는 가장 오래된 도큐먼트를 덮어쓰게 된다. 이 컬렉션은 128KB가 할당되는데, 이로인해 프로파일러가 리소스를 많이 사용하지 못한다.&lt;/p&gt;

&lt;p&gt;150밀리초 이상이 소요된 모든 쿼리를 찾고 싶으면 다음과 같이 한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.system.profile.find({millis:{$gt:150}})
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;느린-쿼리-분석:4b17b39bee401b784b526ec221a2040f&#34;&gt;느린 쿼리 분석&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;EXPLAIN()의 사용과 이해
explain명령은 주어진 쿼리의 경로에 대한 자세한 정보를 제공한다. 바로 들어가서, 앞서 수행했던 쿼리에 대해 explain을 수행하면 얻을 수 있는 결과를 보자&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.values.find({&amp;quot;stock_symbol&amp;quot;:&amp;quot;GOOG&amp;quot;}).sort({data:-1}).limit(1).explain()
{
    &amp;quot;queryPlanner&amp;quot; : {
        &amp;quot;plannerVersion&amp;quot; : 1,
        &amp;quot;namespace&amp;quot; : &amp;quot;stocks.values&amp;quot;,
        &amp;quot;indexFilterSet&amp;quot; : false,
        &amp;quot;parsedQuery&amp;quot; : {
            &amp;quot;stock_symbol&amp;quot; : {
                &amp;quot;$eq&amp;quot; : &amp;quot;GOOG&amp;quot;
            }
        },
        &amp;quot;winningPlan&amp;quot; : {
            &amp;quot;stage&amp;quot; : &amp;quot;SORT&amp;quot;,
            &amp;quot;sortPattern&amp;quot; : {
                &amp;quot;data&amp;quot; : -1.0
            },
            &amp;quot;limitAmount&amp;quot; : 1,
            &amp;quot;inputStage&amp;quot; : {
                &amp;quot;stage&amp;quot; : &amp;quot;SORT_KEY_GENERATOR&amp;quot;,
                &amp;quot;inputStage&amp;quot; : {
                    &amp;quot;stage&amp;quot; : &amp;quot;COLLSCAN&amp;quot;,
                    &amp;quot;filter&amp;quot; : {
                        &amp;quot;stock_symbol&amp;quot; : {
                            &amp;quot;$eq&amp;quot; : &amp;quot;GOOG&amp;quot;
                        }
                    },
                    &amp;quot;direction&amp;quot; : &amp;quot;forward&amp;quot;
                }
            }
        },
        &amp;quot;rejectedPlans&amp;quot; : []
    },
    &amp;quot;serverInfo&amp;quot; : {
        &amp;quot;host&amp;quot; : &amp;quot;LDI&amp;quot;,
        &amp;quot;port&amp;quot; : 27017,
        &amp;quot;version&amp;quot; : &amp;quot;3.2.11&amp;quot;,
        &amp;quot;gitVersion&amp;quot; : &amp;quot;009580ad490190ba33d1c6253ebd8d91808923e4&amp;quot;
    },
    &amp;quot;ok&amp;quot; : 1.0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;인덱스 생성후 결과&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.values.createIndex({stock_symbol: 1})
{
    &amp;quot;queryPlanner&amp;quot; : {
        &amp;quot;plannerVersion&amp;quot; : 1,
        &amp;quot;namespace&amp;quot; : &amp;quot;stocks.values&amp;quot;,
        &amp;quot;indexFilterSet&amp;quot; : false,
        &amp;quot;parsedQuery&amp;quot; : {
            &amp;quot;stock_symbol&amp;quot; : {
                &amp;quot;$eq&amp;quot; : &amp;quot;GOOG&amp;quot;
            }
        },
        &amp;quot;winningPlan&amp;quot; : {
            &amp;quot;stage&amp;quot; : &amp;quot;SORT&amp;quot;,
            &amp;quot;sortPattern&amp;quot; : {
                &amp;quot;data&amp;quot; : -1.0
            },
            &amp;quot;limitAmount&amp;quot; : 1,
            &amp;quot;inputStage&amp;quot; : {
                &amp;quot;stage&amp;quot; : &amp;quot;SORT_KEY_GENERATOR&amp;quot;,
                &amp;quot;inputStage&amp;quot; : {
                    &amp;quot;stage&amp;quot; : &amp;quot;FETCH&amp;quot;,
                    &amp;quot;inputStage&amp;quot; : {
                        &amp;quot;stage&amp;quot; : &amp;quot;IXSCAN&amp;quot;,
                        &amp;quot;keyPattern&amp;quot; : {
                            &amp;quot;stock_symbol&amp;quot; : 1.0
                        },
                        &amp;quot;indexName&amp;quot; : &amp;quot;stock_symbol_1&amp;quot;,
                        &amp;quot;isMultiKey&amp;quot; : false,
                        &amp;quot;isUnique&amp;quot; : false,
                        &amp;quot;isSparse&amp;quot; : false,
                        &amp;quot;isPartial&amp;quot; : false,
                        &amp;quot;indexVersion&amp;quot; : 1,
                        &amp;quot;direction&amp;quot; : &amp;quot;forward&amp;quot;,
                        &amp;quot;indexBounds&amp;quot; : {
                            &amp;quot;stock_symbol&amp;quot; : [ 
                                &amp;quot;[\&amp;quot;GOOG\&amp;quot;, \&amp;quot;GOOG\&amp;quot;]&amp;quot;
                            ]
                        }
                    }
                }
            }
        },
        &amp;quot;rejectedPlans&amp;quot; : []
    },
    &amp;quot;serverInfo&amp;quot; : {
        &amp;quot;host&amp;quot; : &amp;quot;LDI&amp;quot;,
        &amp;quot;port&amp;quot; : 27017,
        &amp;quot;version&amp;quot; : &amp;quot;3.2.11&amp;quot;,
        &amp;quot;gitVersion&amp;quot; : &amp;quot;009580ad490190ba33d1c6253ebd8d91808923e4&amp;quot;
    },
    &amp;quot;ok&amp;quot; : 1.0
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;MongoDB의 쿼리 옵티마이저와 HINT()
쿼리 옵티마이저는 해당 쿼리를 가장 효율적으로 실행하기 위해 어떤 인덱스를 사용할 지 결정하는 소프트웨어다. 쿼리에 가장 이상적인 인덱스를 선택하기 위해 쿼리 옵티마이저는 다음과 같이 아주 간단한 규칙을 사용한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;scanAndOrder를 피한다. 즉, 쿼리가 정렬을 포함하고 있으면 인덱스를 사용한 정렬을 시도한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;유용한 인덱스 제한 조건으로 모든 필드를 만족시킨다. 즉, 쿼리 실렉터에 지정된 필드에 대한 인덱스를 사용하도록 노력한다.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;쿼리가 범위를 내포하거나 정렬을 포함하면 마지막 키에 대해 범위나 정렬에 도움이 되는 인덱스를 선택하라&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;hint는 쿼리 옵티마이저로 하여금 강제로 특정 인덱스를 사용하도록 만드는 것이다. 특정 인덱스를 선택하지 않은 경우가 명확하지 않을 경우 사용하면 된다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.values.find({&amp;quot;stock_symbol&amp;quot;:&amp;quot;GOOG&amp;quot;}).sort({data:-1}).limit(1).hint({stock_symbol:1}).explain()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;쿼리 최적화는 항상 애플리케이션에 따라 다르게 수행되어야 하지만, 여기서 제시한 아이디어와 기법들은 쿼리를 튜닝하는데 도움이 될 것이다. 쿼리를 프로파일하고 explain을 실행하는 것을 습관화해야한다.&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>업데이트, 원자적 연산, 삭제</title>
      <link>http://kwsstudy.github.io/post/%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8,-%EC%9B%90%EC%9E%90%EC%A0%81-%EC%97%B0%EC%82%B0,-%EC%82%AD%EC%A0%9C/</link>
      <pubDate>Sun, 27 Nov 2016 11:00:00 +0900</pubDate>
      
      <guid>http://kwsstudy.github.io/post/%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8,-%EC%9B%90%EC%9E%90%EC%A0%81-%EC%97%B0%EC%82%B0,-%EC%82%AD%EC%A0%9C/</guid>
      <description>

&lt;h2 id=&#34;6-1-도큐먼드-업데이트:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.1 도큐먼드 업데이트&lt;/h2&gt;

&lt;p&gt;1 . MongoDB에서 업데이트를 하려면 두 가지 방법을 사용할 수 있다. 도큐먼트 전체를 대치하든지 아니면 도큐먼트 내의 특정 필드를 수정하기 위해 업데이트 연산자를 조합해서 사용할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;user_id = BSON::ObjectId(&amp;quot;4c4b1476238d3b4dd5000001&amp;quot;)
doc = @user.find_one({:_id =&amp;gt; user_id})

doc[&#39;email&#39;] = &#39;mongodb-user@10gen.com&#39;
@users.update({:_id =&amp;gt; user_id}, doc, :safe =&amp;gt; true)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;도규먼트를 수정하는 방법 &lt;br /&gt;
유저의 _id를 가지고 먼저 도큐먼트를 검색한다. 그런 다음 불러온 도큐먼트의 email속성을 수정하고, 수정된 도큐먼트를 update 메소드의 파라미터로 넘겨주게 된다. 마지막 라인은 유저 컬렉션에서 주어진 _id로 도큐먼트를 찾아서 새로이 제공하는 도큐먼트로 대치하라는 의미이다.(도규먼트를 수정하는 방법)&lt;/li&gt;
&lt;li&gt;연산자로 수정하는 방법 &lt;br /&gt;
업데이트 연산자 중에 하나인 $set을 사용했다. 이 경우에 업데이트 요청은 주어진 조건으로 유저 도큐먼트를 찾아서 email필드를 mongodb-ser@10gen.com으로 수정하라 와 같은 방식으로 좀 더 특정 필드를 목표로 하고 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;@users.update({:_id =&amp;gt; user_id}, {&#39;$set&#39; =&amp;gt; {:email =&amp;gt; &#39;mongodb-user@10gen.com&#39;}}, :safe =&amp;gt; true)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2 . 유저의 주소 리스트에 배송 주소를 하나 더 추가하려고 한다. 도큐먼트 대치 방식은 다음과 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;doc = @users.find_one({:_id =&amp;gt; user_id})

new_address = {
   :name =&amp;gt; &amp;quot;work&amp;quot;,
   :street =&amp;gt; &amp;quot;17 W. 18th St.&amp;quot;,
   :city =&amp;gt; &amp;quot;New York&amp;quot;,
   :state =&amp;gt; &amp;quot;NY&amp;quot;,
   :zip =&amp;gt; 10011
}

doc[&#39;shipping_addresses&#39;].append(new_address)
@users.update({:_id =&amp;gt; user_id}, doc)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;타깃 방식은 다음과 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;@users.update({:_id =&amp;gt; user_id},
   {&#39;$push&#39; =&amp;gt; {:addresses =&amp;gt;
      {:name =&amp;gt; &amp;quot;work&amp;quot;,
      :street =&amp;gt; &amp;quot;17 W. 18th St.&amp;quot;,
      :city =&amp;gt; &amp;quot;New York&amp;quot;,
      :state =&amp;gt; &amp;quot;NY&amp;quot;,
      :zip =&amp;gt; 10011
      }
   } 
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;대치 방식은 이전과 같이 서버로부터 유저 도큐먼트를 가져와서 수정을 한 후에 다시 서버로 보낸다. 여기에서 업데이트문은 이메일 주소를 업데이트하기 위해 사용했던 업데이트문과 같다. 이와는 다르게 타깃 방식의 업데이트는 새 주소를 기존의 addresses배열에 추가하기 위해 $push라고 하는 또 다른 업데이트 연산자를 사용한다.&lt;/p&gt;

&lt;h2 id=&#34;6-2-전자상거래-업데이트:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.2 전자상거래 업데이트&lt;/h2&gt;

&lt;h4 id=&#34;6-2-1-상품과-카테고리:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.2.1 상품과 카테고리&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;상품의 평점 평균 &lt;br /&gt;
상품은 여러가지 업데이트 전략이 적용될 수 있다. 상품 정보를 수정할 수 있는 인터페이스가 관리자에게 제공된다고 가정하면,가장 쉬운 업데이트는 현재의 상품 도큐먼트를 가지고 와서 관리자에 의해 수정된 것과 통합한 후에 새로운 도큐먼트로 이전의 도큐먼트를 대치하는 것이다.다른 경우로는 단지 몇가지 속성만 바꾸는 경우인데,이때는 타깃 방식의 업데이트가 사용되어야 한다. 상품의 평점의 평균을 구하는 경우가 여기에 속한다. 유저는 상품 리스트를 상품의 평균 평점으로 정렬할 필요가 있기 때문에 평점을 상품 도큐먼트에 저장하고, 리뷰가 추가되거나 삭제될 때마다 그 값을 업데이트 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascipt&#34;&gt;average = 0.0
count = 0
total = 0
cursor = @reviews.find({:product_id =&amp;gt; product_id}, :fields =&amp;gt; [&amp;quot;rating&amp;quot;])
while cursor.has_next? &amp;amp;&amp;amp; review = cursor.next()
   total += review[&#39;rating&#39;]
   count += 1
end

average = total / count
@product.update({:_id =&amp;gt; BSON::ObjectId(&amp;quot;4c4b1476238d3b4dd5003981&amp;quot;)},
   ${&amp;quot;$set&amp;quot; =&amp;gt; {:total_reviews =&amp;gt; count, :average_review =&amp;gt; average}})

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이 코드는 각 상품 리뷰 도큐먼트로부터 rating 필드를 집계해서 평균을 구한다. 반복문에서는 상품에 대한 리뷰의 총 개수도 계산하는데, 이로 인해 count함수에 대한 추가적인 데이터베이스 호출을 안해도 된다. 리뷰의 총 개수와 평균 평점으로 $set을 사용해서 타깃 업데이트를 수행할 수 있다.&lt;/p&gt;

&lt;p&gt;다른 전략도 가능하다.예를 들어, 상품 도큐먼트에 리뷰 평점의 총합을 보관하는 필드를 추가할 수도 있다. 새 리뷰가 인서트 된 후에 상품에 대한 리뷰의 총 개수와 평점의 총합을 질의하고 평균을 계산해서 다음과 같이 셀렉터를 사용해 업데이트를 수행 할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt; ${&amp;quot;$set&amp;quot; =&amp;gt; {:average_review =&amp;gt; average, :ratings_total =&amp;gt; total}, &#39;$inc&#39; =&amp;gt; {:total_reviews =&amp;gt; 1}})
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;카테고리 계층구조 &lt;br /&gt;
대부분의 데이터베이스에서는 카테고리 계층구조를 쉽게 표현할 수 있는 방법이 없다.도규먼트 구조가 어느 정도 도움이 되긴 하지만 MongoDB에서도 이것은 마찬가지이다. 도큐먼트는 각 카테고리가 조상 카테고리의 리스트를 가지고 있기 때문에 읽기에 최적화되어 있다. 한가지 까다로운 요구사항은 모든 좃ㅇ 카테고리를 최신으로 가지고 있는 것이다.이것이 어떻게 이루어지는지 다음의 예를 통해 살펴보자.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;우선, 주어진 카테고리에 대해 조상 리스트를 업데이트하기 위한 일반적인 방법이 필요하다. 한 가지 가능한 방법은 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;def generate_ancestors(_id, parent_id)
   ancestor_list = []
   while parent = @categories.find_one(:_id =&amp;gt; parent_id) do
      ancestor_list.unshift(parent)
      parent_id = parent[&#39;parent_id&#39;]
   end
   
   @categories.update({:_id =&amp;gt; _id}, {&#39;$set&#39; {:ancestors =&amp;gt; ancestor_list}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;이 메소드는 카테고리 계층구조를 거슬러 올라가면서 루트 노드에 도달할 때까지 각 노드의 parent_id 속성을 연달아 질의하여 조상 리스트를
구한다. 이렇게 해서 조상들의 순서가 있는 리스트를 구하고 그 결과를 ancestor_list에 저장한다. 마지막으로 $set을 사용해서 카테고리의 ancestors 속성에 저장한다.&lt;/p&gt;

&lt;p&gt;이제 기본적인 것을 갖추었으니 새 카테고리를 인서트하는 프로세스를 살펴보자. 그림 6-1과 같이 간단한 카테고리 계층구조가 있다고 하자.
(책 144페이지 참조)&lt;/p&gt;

&lt;p&gt;이 카테고리 구조에 Gardening이라는 카테고리를 Home 카테고리 아래에 새로 추가한다고 하자.새로운 카테고리 도큐먼트를 삽입하고, 좀 전에 우리가 이미 살펴본대로 그 카테고리의 조상 리스트를 생성하는 메소드를 실행한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;category = {
   :parent_id =&amp;gt; parent_id,
   :slug =&amp;gt; &amp;quot;gardening&amp;quot;,
   :name =&amp;gt; &amp;quot;Gardening&amp;quot;,
   :description =&amp;gt; &amp;quot;All gardening implements, tools, seeds, and soil.&amp;quot;
}
gardening_id = @categiries.insert(category)
generate_ancestors(gardening_id, parent_id)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Outdoorss카테고리를 Gardening카테고리 아래로 옮기려고 한다면 어떻게 될까?이것은 카테고리에 대해서 그 조상 리스트를 변경해야 하기 때문에 복잡해질 가능성이 많다.Outdoors 카테고리의 parent_id의 값을 Gardening의 _id 값으로 변경하는 것으로 시작할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;@categories.update({:_id =&amp;gt; outdoors_id}, {&#39;$set&#39; =&amp;gt; {:parent_id =&amp;gt; gardening_id}})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Outdoors 카테고리를 옮겼기 때문에 Outdoors의 모든 자손 노드들은 유효하지 않은 조상 리스트를 갖게 된다. 이것은 조상 리스트에 Outdoors를 가지고 있는 모든 카테고리를 질의하여 불러온 다음, 이 카테고리들의 조상 리스트를 재 계산하여 수정할 수 있다.
MongoDB의 강력한 배열에 대한 질의로 이것이 간단하게 된다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;@categories.find({&#39;ancestors.id&#39; =&amp;gt; outdoors_id}).each do |category|
generate_ancestors(category[&#39;_id&#39;], outdoors_id)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;하지만 이제 카테고리 이름을 변경해야 한다면 어떻게 해야 할까? Outdoors를 TheGreatOutdoors로 수정하려 한다면 다른 카테고리의 조상 카테고리 리스트에 있는 모든 Outdoors를 TheGreateOutdoors로 변경해야 한다. 이 부분에서 당연하게 이런 생각이 들지도 모르겠다.
비정규화를 하면 나타나는 문제점이 바로 이런것들이지 하지만 조상 리스트를 다시 계산할 필요없이 이 업데이트를 수행할 수 있다는 것을 알게되면 이런 생각이 조금은 풀릴 것이다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;doc = @categories.find_one({:id =&amp;gt; outdoors_id})
doc[&#39;name&#39;] = &amp;quot;The Great Outdoors&amp;quot;
@categories.update({:_id =&amp;gt; outdoors_id}, doc)

@categories.update({&#39;ancestors.id&#39; =&amp;gt; outdoors_id},
{&#39;$set&#39; =&amp;gt; {&#39;ancestors.$&#39; =&amp;gt; doc}}, multi =&amp;gt; true)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;우선 Outdoors 도큐먼트를 찾아서 name속성을 로컬 도큐먼트에서 바꿔주소 대치 방식으로 업데이트를 수행한다. 그리고서 수정된 Outdoors 도큐먼트를 이용해서 모든 조상 리스트에 나타나는 Outdoors를 바꿔주는데, 이것은 위치 연산자와 다중 업데이트를 통해 수행한다.다중 업데이트가 무엇인지 이해하는 것은 어렵지 않다. 실렉터와 일치하는 도큐먼트를 모두 수정하기를 원할 경우 :multi =&amp;gt; true로 지정하면 되는 것을 기억하기 바란다.&lt;/p&gt;

&lt;p&gt;위치 연산자는 이것보다는 조금 더 까다롭다. 주어진 카테고리의 조상 리스트에서 Outdoor 카테고리가 나타나는 위치를 알 수 있는 방법이 없다는 것을 생각하기 바란다. 따라서 어떤 도큐먼트에 대해 배열 내에서 Outdoor 카테고리의 위치를 동적으로 지정할 수 있는 업데이트 연산자가 필요하며, 이런 경우에 위치 연산자를 사용하면 된다. 위의 코드에서 ancestors.$의 $가 위치 연산자인데, 쿼리 실렉터와 일치하는 배열 인덴스를 그 자신으로 대치해 업데이트를 가능하게 한다.&lt;/p&gt;

&lt;h4 id=&#34;6-2-2-리뷰:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.2.2 리뷰&lt;/h4&gt;

&lt;p&gt;모든 리뷰가 동등한 것은 아니기 때문에 유저로 하여금 리뷰에 대해 추천하는 것을 허용하게 된다. 이러한 추천은 기초적인 것으로, 단지 어떤 리뷰가 도움이 되었는지를 가리킬 뿐이다. 리뷰 데이터를 모델링할 때 추천 수와 추천자의 아이디를 리스트로 가지고 있도록 만들었는데,리뷰 도큐먼트에서 이와 관련한 부분은 다음과 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;{helpful_votes : 3,
voter_ids: [ ObjectId(&amp;quot;4c4b1476238d3b4dd5000041&amp;quot;),
             ObjectId(&amp;quot;7a4f0376238d3b4dd5000003&amp;quot;),
             ObjectId(&amp;quot;92c21476238d3b4dd5000032&amp;quot;),
           ]}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;타깃 방식의 업데이트를 사용해서 추천과 관련한 레코드를 저장할 수 있다.이 전략은 $push 연산자를 사용해서 추천자의 ID를 리스트에 추가하고 $inc 연산자를 사용해서 추천 수를 하나 증가하는데,이 두 가지가 하나의 업데이트 연산을 통해 이루어진다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.reviews.update({ _id : ObjectId(&amp;quot;4c4b1476238d3b4dd5000041&amp;quot;)},
    {$push : { voter_ids : ObjectId(&amp;quot;4c4b1476238d3b4dd5000001&amp;quot;)},
      $inc: {helpful_votes: 1}
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위의 업데이트 연산은 추천자가 이 리뷰에 대해 추천한 적이 없는 경우에만 수행되어야만 비로소 완전해진다. 이것을 위해 쿼리 실렉터를 수정해서 voter_ids 배열에 추가하려고 하는 아이디가 없는 경우에만 일치하도록 수정해야 한다. $ne 쿼리 연산자를 사용하면 이것이 쉽게 된다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;query_selector = {_id : ObjectId(&amp;quot;4c4b1476238d3b4d5000041&amp;quot;),
   voter_ids :{$ne:ObjectId(&amp;quot;4c4b1476238d3b4dd5000001&amp;quot;)}
db.reviews.update({ query_selector,
    {$push : { voter_ids : ObjectId(&amp;quot;4c4b1476238d3b4dd5000001&amp;quot;)},
      $inc: {helpful_votes: 1}
})
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;6-2-3-오더:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.2.3 오더&lt;/h4&gt;

&lt;p&gt;오더의 아이템 배열에 저장할 상품 도큐먼트를 생성하고 타깃 업데이트를 실행하는데, 이때의 업데이트는 upsert라는 연산을 사용한다. 업서트는 업데이트할 도큐먼트가 존재하지 않을 경우 새로운 도큐먼트를 인서트한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;cart_item = {
   _id : ObjectId(&amp;quot;4c4b1476238d3b4dd5003981&amp;quot;),
   slug : &amp;quot;wheel-barrow-9092&amp;quot;,
   sku : &amp;quot;9092&amp;quot;,
name: &amp;quot;Extra Large Wheel Barrow&amp;quot;,
   pricing:{
   retail : 589700,
   sale : 489700
   }
}

selector = {user_id : ObjectId(&amp;quot;4c4b1476238d3b4dd5000001&amp;quot;),
            state : &#39;CART&#39;,
            &#39;line_items.id&#39; :
               {&#39;$ne&#39; : ObjectId(&amp;quot;4c4b1476238d3b4dd5003981&amp;quot;)}  
            }

update = {&#39;$push&#39; : {&#39;line_items&#39; : cart_item}}
db.orders.update(selector, update, true, false)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;쿼리 실레거를 생성하고 도큐먼트 업데이트를 따로 하는 것은 코드를 좀 더 명확하게 하기 위해서다.업데이트 도큐먼트는 카드 아이템 도큐먼트를 오더 아이템의 배열에 추가한다. 쿼리 실렉터가 보여주듯이 이 업데이트는 해당 아잍ㅁ이 오더 아이템 배열에 아직 존재하지 핞을 경우에만 성공적으로 수행된다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;cart_item = {
   _id : ObjectId(&amp;quot;4c4b1476238d3b4dd5003981&amp;quot;),
   line_items : [{
      _id : ObjectId(&amp;quot;4c4b1476238d3b4dd5003981&amp;quot;)
      slug : &amp;quot;wheel-barrow-9092&amp;quot;,
      sku : &amp;quot;9092&amp;quot;,
      name: &amp;quot;Extra Large Wheel Barrow&amp;quot;,
      pricing:{
      retail : 589700,
      sale : 489700
      }
   }]
}

selector = {user_id : ObjectId(&amp;quot;4c4b1476238d3b4dd5000001&amp;quot;),
            state : &#39;CART&#39;,
            &#39;line_items.id&#39; : ObjectId(&amp;quot;4c4b1476238d3b4dd5003981&amp;quot;)}  

update = {&#39;$inc&#39; : {&#39;line_items.$.qty&#39; : 1, sub_total : cart_item[&#39;pricing&#39;][&#39;sale&#39;]}}

db.orders.update(selector, update, true, false)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위의 코드에서 $inc 연산자를 사용해서 개별 오더 아이템에 대한 오더 액수의 합과 전체 개수를 업데이트하는 것을 알 수 있다.&lt;/p&gt;

&lt;h2 id=&#34;6-3-원자적-도큐먼트-프로세싱:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.3 원자적 도큐먼트 프로세싱&lt;/h2&gt;

&lt;p&gt;MongoDB에서 반드시 필요한 업데이트 툴은 findAndModify명령이다. 이 명령을 통해서 도큐먼트를 자동으로 업데이트하고 업데이트 된 도큐먼트를 리턴하는 것이 한번에 가느해진다.&lt;/p&gt;

&lt;h4 id=&#34;6-3-1-오더-상태-전이-br:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.3.1 오더 상태 전이 &lt;br /&gt;&lt;/h4&gt;

&lt;p&gt;모든 상태 전이는 유효한 초기 상태를 확인하는 쿼리와 상태를 변경하는 업데이트,이럭게 두 부분으로 되어 있다.
 - 유저가 체크아웃 스크린에서 보고 있는 액수를 승인해야 한다.
 - 승인 과정에서는 카트의 내용이 변경되어서는 안된다.
 - 승인 절차가 실패할 경우 카트의 이전 상태로 돌아가야 한다.
 - 크레딧 카드가 성공적으로 승인될 경우 지불 정보가 오더에 저장되고 오더의 상태는 SHPIMENT PENDING로 바뀌어야 한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.orders.findAndModify({
   query : {user_id : ObjectId(&amp;quot;4c4b1476238d3b4dd5000001&amp;quot;), state : &amp;quot;CART&amp;quot;},
   update : {&amp;quot;$sest&amp;quot; : {&amp;quot;state&amp;quot; : &amp;quot;PRE-AUTHRIZE&amp;quot;}, new : true}
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;성공하면 findAndModify는 상태가 전이된 오더 객체를 리턴하게 된다. 일단 오더가 PRE-AUTHHORIZE 상태에 놓이게 되면 유저는 카트의 내용을 변경할 수 없다.이것은 카트에 대한 모든 업ㄷ이트는 오더의 상태가 CART일 때만 가능하기 때문이다.이제 승인 전 단계에서 오더 객체를 가지고 다양한 총계를 계산한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.orders.findAndModify({
   query : {user_id : ObjectId(&amp;quot;4c4b1476238d3b4dd5000001&amp;quot;),
   total : 99000,
   state : &amp;quot;PRE-AUTHRIZE&amp;quot;} ,
   update : {&amp;quot;$sest&amp;quot; : {&amp;quot;state&amp;quot; : &amp;quot;AUTHRIZING&amp;quot;}, new : true}
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;만일 두 번째 수행한 findAndModify가 실패하면 오더의 상태를 CART로 되돌리고 유저에게 업데이트된 총액을 알려줘야 한다.하지만 성공할 경우에는 승인된 총액이 유저에게 보여준 액수와 동일한 것을 의미하고, 이것은 실제의 승인 API호출을 할 수 있다는 것을 의미한다.따라서 애플리케이션에서 유저의 신용 카드에 대한 신인 요청을 할 수 있다.
하지만 승인이 성공하면 승인 정보를 오더에 저장하고 다음 단계로 넘어간다. 아래예에서 제시되는 전략은 한 번의 findAndModify호출로 두가지를 수행한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;auth_doc = {ts : new Date(),
            cc : 3432003948284040,
            id : 2923838291029384483949348,
            gateway : &amp;quot;Authorize.net&amp;quot;}
db.orders.findAndModify({
   query : {user_id : ObjectId(&amp;quot;4c4b1476238d3b4dd5000001&amp;quot;), state : &amp;quot;AUTHORIZING&amp;quot;},
   update : {&amp;quot;$sest&amp;quot; : {&amp;quot;state&amp;quot; : &amp;quot;PRE-SHIPPING&amp;quot;}, &amp;quot;authorization&amp;quot;: auth_doc}
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;MongoDB의 어떤 기능들로 인해 이 트랜잭션 프로세스가 용이해지는지 알고 있어야 한다. 하나의 도큐먼트를 원자적으로 수정할 수 있다는 점, 한번의 연결에 일관적인 읽기를 보장한다는 점, 그리고 이들 연산이 MongoDB에서 제공하는 단일 도큐먼트 원자성에 적합하도록 해주는 도큐먼트 구조 그 자체, 이렇게 세가지이다.&lt;/p&gt;

&lt;p&gt;####6.3.2 재고 관리 &lt;br /&gt;
 PASS&lt;/p&gt;

&lt;h2 id=&#34;6-4-실제적인-세부사항-mongodb업데이트와-삭제:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.4 실제적인 세부사항 : MongoDB업데이트와 삭제&lt;/h2&gt;

&lt;h4 id=&#34;6-4-1-업데이트-타입과-옵션:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.4.1 업데이트 타입과 옵션&lt;/h4&gt;

&lt;p&gt;MongDB는 타깃 방식과 대치 방식의 업데이트를 지원한다. 타깃 업데이트는 하나 혹은 그 이상의 업데이트 연산자를 사용해서 정의한다.
대치 업데이트는 업데이트의 쿼리 실렉터와 일치하는 도큐먼트를 대치하기 위해 사용될 도큐먼드로 정의한다.&lt;/p&gt;

&lt;p&gt;업데이트 도큐먼트가 모호하면 업데이트는 실패한다는 점을 알기 바란다. 아래에서 업데이트 연산자인 $addToSet을 대치 방식의 의미를 갖는 {name : &amp;lsquo;Pitchfork&amp;rsquo;}과 합쳤다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({}, {name : &#39;Pitchfork&#39;, $addToSet : {tags : &#39;cheap&#39;})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;원래 의도가 도큐먼트의 이름을 바꾸려는 것이었다면 다음과 같이 $set 연산자를 사용해야한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({}, {$set : {name : &#39;Pitchfork&#39;}, $addToSet : {tags : &#39;cheap&#39;})
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;다중업데이트
업데이트는 기본적으로 쿼리 실렉터와 일치하는 첫 번째 도큐먼트만을 업데이트 한다. 일치하는 모든 도큐먼트를 업데이트하려면 다중 업데이트라고 명확하게 알려줘야 한다. 셸에서는 이것을 우해 업데이트 메소드의 네 번째 파라미터 값을 true로 념겨준다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({}, {$addToSet : {tags : &#39;cheap&#39;}, false, true)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;UPSERT
아이템이 없으면 새로 추가하고 이미 있다면 업데이트를 하는 것은 일반적으로 필요한 일이다. 구현하기 까다로운 이러한 패턴은 보통 MongoDB의 업서트로 처리한다. 쿼리 실렉통허 일치하는 도큐먼트가 발견되면 업데이트가 정상적으로 수행된다. 하지만 일치하는 도큐먼트가 발견되지 않을 경우 새로운 도큐먼트를 삽입된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({slug : &#39;hammer&#39;}, {$addToSet : {tags : &#39;cheap&#39;}, true)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;6-4-2-업데이트-연산자:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.4.2 업데이트 연산자&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;$INC &lt;br /&gt;
$inc 연산자는 수치를 증가하거나 감소할 때 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({slug : &amp;quot;shovel&amp;quot;}, {$inc : {review_count : 1})
db.users.update({username : &#39;moe&#39;}, {$inc : {password_retires: -1})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;하지만 다음과 같이 수치를 임의로 더하거나 빼는 데도 사용할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.readings.update({_id : 324}, {$inc : {temp : 2.7435})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$inc는 편리하고 효율적이다. 이 연산자는 도큐먼트의 크기를 변경하는 일이 거의 없기 때문에 디스크에서 해당 부분만 적용이 되어 지정된 값만 영향을 받는다.
쇼핑 카트에 아이템을 추가하는 것을 구현할 때 그랬듯이 $inc를 업서트와 함께 사용할 수 있다. 앞의 예제를 업서트와 함께 사용하는 것으로 바꾸면 다음과 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.readings.update({_id : 324}, {$inc : {temp : 2.7435}, true)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;$SET 과 $UNSET  &lt;br /&gt;
도큐먼트에서 특정 키의 값을 정해주려면 $set을 사용한다. 키에 대한 값으로는 정수에서부터 서브도큐먼트와 배열에 이르기까지 어떤 것이라도 가능하다.즉, 다음과 같은 업데이트가 모두 가능하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.readings.update({_id : 324}, {$set : {temp : 97.6}})
db.readings.update({_id : 325}, {$set : {temp : {f : 212, c : 100}})
db.readings.update({_id : 324}, {$set : {temps : [97.6, 98.4, 99.1]})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$unset은 도큐먼트에서 해당 키를 삭제한다. 아래의 예는 readings라는 컬렉션 내의 한 도큐먼트에서 temp키를 삭제하는 것을 보여준다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.readings.update({_id : 324}, {$unset : {temp : 1})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;임베디드된 도큐먼트나 배열에 대해서도 $unset을 사용할 수 있다. 이 경우에 닷 표기법을 사용해서 내부 객체를 지정한다. 다음과 같이 2개의 도큐먼트가 컬렉션에 있다면,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;{_id : 325, &#39;temp&#39; : {f:212, c:100}}
{_id : 326, temps : [97.6, 98.4, 99.1]}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;첫 번째 도큐먼트에서 화씨를 삭제하고 두 번째 도큐먼트에서 인덱스가 0인 값을 삭제하려면 다음과 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.reading.update({_id : 325},{$unset : {&#39;temp.f&#39; : 1})
db.reading.update({_id : 326},{$pop : {temps : -1})
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;$rename  &lt;br /&gt;
키의 이름을 바꿀 필요가 있을 경우에는 $rename을 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javasccript&#34;&gt;db.readings.upadate({_id : 324}, {$rename : {&#39;temp&#39; : &#39;temperature&#39;})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;서브 도큐먼트도 다음과 같이 이름을 변경할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javasccript&#34;&gt;db.readings.upadate({_id : 324}, {$rename : {&#39;temp.f&#39; : &#39;temp.farenheit&#39;})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;#####배열 업데이트 연산자
 - $push AND $pushAll  &lt;br /&gt;
배열에 값을 추가해야 한다면 $push나 $pushAll을 사용한다. $push는 배열에 하나의 값을 추가하는 반면,$pushAll은 하나 이상의 값을 추가하는 데 사용한다. 예를 ㄷㄹ어, 부삽 상품에 새로운 태그를 추가하는 것은 아주 쉽다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({slug : &#39;shovel&#39;}, {$push : {&#39;tags&#39; : &#39;tools&#39;}})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;태그를 여러 개 추가하려면 다음과 같이 하면 된다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({slug : &#39;shovel&#39;}, {$pushAll : {&#39;tags&#39; : [&#39;tools&#39;,&#39;dirt&#39;,&#39;garden&#39;]}})
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;$addToSet과 $each  &lt;br /&gt;
$addToSet은 배열에 값을 첨가하지만 이것을 좀 더 분별적으로 수행한다. 즉, 배열에 존재하지 않을 경우에만 값을 첨가한다.따라서 만일 부삽 상품이 이미 tool이라는 태그 값을 가지고 있으면 아래의 업데이트는 도큐먼트를 수정하지 않는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({slug : &#39;shovel&#39;}, {$addToSet: {&#39;tags&#39; : &#39;tools&#39;}})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;위의 경우를 하나 이상의 값에 대해서 수행하고자 한다면 아래에서와 같이 $addToSet을 $each 연산자와 함께 사용해야 한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({slug : &#39;shovel&#39;}, {$addToSet: {&#39;tags&#39; : {$each : [&#39;tools&#39;,&#39;dirt&#39;,&#39;garden&#39;]}}})
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;$pop  &lt;br /&gt;
배열에서 아이템을 삭제하는 가장 기본적인 방법은 $pop 연산자를 사용하는 것이다.$push가 배열에 아이템을 첨가하는 것이라면 $pop은 마지막으로 첨가된 아이템을 지운다.많은 경우 $push와 함께 쓰이지만, $pop만을 사용하는 경우도 있다. tags배열이 [&amp;lsquo;tools&amp;rsquo;, &amp;lsquo;dirt&amp;rsquo;, &amp;lsquo;steel&amp;rsquo;]의 값을 갖는다면 아래의 $pop은 steel태그를 삭제할 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({slug : &#39;shovel&#39;}, {$pop : {&#39;tags&#39; : 1}})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$unset에서처럼 $pop의 구문도 {$pop : {&amp;lsquo;elementToRemove&amp;rsquo; : 1}}이다. 하지만 $unset과는 다르게, $pop은 배열의 첫 번째 아이템을 지우기 위해 -1이라는 또 다른 값을 받는다.위의 배열에서 tools 태그를 삭제하는 것은 아래와 같다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({slug : &#39;shovel&#39;}, {$pop : {&#39;tags&#39; : -1}})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$pop에서 한가지 당황스러울 수도 있는 점이 있는데, 그것은 $pop이 배열에서 삭제된 값을 리턴하지 않는다는 점이다. $pop은 스택 구조에서와 같이 동일하게 수행되지는 않는다는 점을 명심해야 한다.
 - $pull과 $pullAll &lt;br /&gt;
$pull은 좀 더 정교한 $pop이라고 볼 수 있다. $pull은 배열에서 원소의 위치 대신값을 지정해서 아이템을 삭제한다. 위의 tags배열에서 태그 dirt를 삭제하고자 하면, 배열 내의 위치를 알 필요 없이 아래에서와 같이 단지 $pull 연산자에게 그것을 삭제할 것을 지시하기만 하면 된다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({slug : &#39;shovel&#39;}, {$pull: {&#39;tags&#39; : &#39;dirt&#39;}})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$pullAll은 $pushAll과 유사한데 삭제할 값의 리스트를 지정할 수 있다. dirt와 garden 태그를 둘 다 삭제하려면 다음과 같이 $pullAll을 사용할 수 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.update({slug : &#39;shovel&#39;}, {$pullAll: {&#39;tags&#39; : [&#39;dirt&#39;,&#39;garden&#39;]}})
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;위치업데이트 &lt;br /&gt;
MongoDB에서 서브도큐먼트의 배열을 사용해서 데이터를 모델링하는 것이 일반적이지만, 서브 도큐먼트를 다루기가 쉽지 않기 때문에 위치 연산자를 사용한다. 위치 연산자를 통해 배열 내의 서브도큐먼트를 업데이트할 수 있다. 닷 표기법을 사용해서 업데이트할 서브도큐먼트를 쿼리 실렉터에서 지정한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;query = {_id : ObjectId(&amp;quot;4c4b1476238d3b4dd5003981&amp;quot;), &#39;line_items.sku&#39; : &#39;10027&#39;}
update = {$set : &#39;line_items.&amp;amp;.quantity&#39; : 5}}
db.orders.update(query, update)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;line_items.$.quantity 에서 $가 위치 연산자다.쿼리 실렉터와 일치하는 도큐먼트가 발견도면 내부적으로 이 위치 연산자를 SKU가 10027인 도큐먼트의 인덱스로 대치하고, 그 결과 해당 도큐먼트를 업데이트하게 된다.&lt;/p&gt;

&lt;h4 id=&#34;6-4-3-findandmodify:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.4.3 findAndModify&lt;/h4&gt;

&lt;p&gt;findAndModify명령을 사용하는 자세한 예제를 앞에서 이미 살펴봤으므로 여기서는 옵션을 살펴보겠다.아래의 옵션 중에서 query와,update 혹은 remove 둘 중의 하나는 반드시 필요한 옵션이다.
 - query = 도큐먼트 쿼리 실렉터이고 디폴트 값은 {}이다
 - update = 업데이트할 내용을 지정하는 도큐먼트이고 디폴트 값은 {}이다.
 - remove = 부울 값으로 true이면 오브젝트를 삭제하고 삭제한 오브젝트를 리턴한다. 디폴트는false
 - new = 부울 값으로 true이면 업데이트를 수행한 후에 업데이트가 적용된 도큐먼트를 리턴한다. 디폴트는 false
 - sort = 정렬 방향을 지정하는 도큐먼트 FindAndModify가 한 번에 하나의 도큐먼트를 수정하기 때문에 이 옵션을 일치하는 도큐먼트 중에서 어떤 것을 처리해야 하는지를 정한ㄴ데 사용된다.
 - fields = 일부의 필드만 필요하다면 이 옵션을 사용해서 필요한 필드를 지정한다.
 - upsert = 부울 값으로 true이면 findAndModify를 업서트처럼 수행한다. 찾고자 하는 도큐먼트가 없는 경우에는 그 도큐먼트를 생성한다.&lt;/p&gt;

&lt;h4 id=&#34;6-4-4-삭제:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.4.4 삭제&lt;/h4&gt;

&lt;p&gt;도큐먼트 삭제가 그다지 어렵지 않다는 점을 알게 되면 안심이 될 것이다. 컬렉션 전체를 지울 수도 있고, remove 메소드에 쿼리 실렉터를 파라미터로 넘겨줘서 컬렉션내의 일부분의 도큐먼트를 지울 수도 있다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.reviews.remove({})
db.reviews.remove({user_id : ObjectId(&#39;4c4b1476238d3b4dd5000001&#39;)})
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;6-4-5-동시성-원자성-고립:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.4.5 동시성, 원자성, 고립&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;MongoDB에서 동시성이 어떻게 수행되는지 이해하는 것이 중요하다. MongoDB 2.0에서는 잠금 전략이 상당히 정교하지 못하다. 하나의 글로벌 읽기-쓰기 잠금이 mongod인스턴스 전체를 관장한다.이것이 의미하는 바는 어느 한 시점에서 데이터베이스는 하나의 쓰기 혹은 다수의 릭기를 허용하지만,둘 다 허용하지는 않는다는 것이다.
어떤 램에 있는 내부적인 매핑 정보를 가지고 있어서, 램에 없는 도큐먼트에 대한 쓰기나 읽기 연산 요청이 들어오면 그 도큐먼트가 메모리로 페이징될때까지 다른 연산을 수행한다.&lt;/li&gt;
&lt;li&gt;두번째 최적화는 쓰기 잠금을 양보하는 것이다. 쓰기 연산의 시간이 오래 걸리면 다른 모든 읽기와 쓰기 연산은 원래의 쓰기가 완료될 때까지 블록된다. 모든 삽입,업데이트,삭제 연산은 쓰기 잠금을 수행한다. 삽입 연산은 시간이 오래 걸리는 경우가 거의 없다.. 하지만 업데이나 삭제의 경우 전체 걸렉션에 영향을 미치는 경우에는 오랫동안 실행 될 수 있다.이 문제에 대한 현재의 해결책은 오랜 시간이 소요되고 있는 연산을 주기적으로 다른 읽기와 쓰기에게 양보하는 것이다. 연산을 양보할 때 잠시 연산을 멈추고 락을 해제했다가 나중에 연산을 재개한다.
하지만 도큐먼트를 업ㄷ이트하고 삭제할 때 이러한 양보는 장단점이 있다. 어떤 연산이 수행되기 전에 반드시 모든 도큐먼트를 업데이트하거나 삭제해야만 하는 상황을 쉽게 생각해볼 수 있다.이런 경우에 $atomic이라고 하는 특수한 옵션을 사용해서 해당 연산이 양보되지 못하도록한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.reviews.remove({user_id : ObjectId(&#39;4c4b1476238d3b4dd5000001&#39;),
{$atomic : true}})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;다중 업데이트에 대해서도 동일하게 적용할 수 있다. 이것은 다중 업데이트가 모두 한 연산으로 완료되게끔 한다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.reviews.remove({$atomic : true},{$set : {rating : 0}}, false, true),
{$atomic : true}})
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;6-4-6-업데이트-성능:8357e8f2721acaa53f8208e45d840e2f&#34;&gt;6.4.6 업데이트 성능&lt;/h4&gt;

&lt;p&gt;디스크 상의 도큐먼트를 업데이트할 때 본질적으로 세 가지 종류가 있다.
 1. 가장 효율적인 것인데, 하나의 값만 수정하고 전체 BSON 도큐먼트의 크기는 변하지 않을때다.가장 일반적인 $inc 연산자를 사용할 때 발생한다. $inc는 단지 정수 값을 증가시키기 때문에 이 값이 디스크 상에서 차지하는 크기에는 변함이 없다.만일 이 정수가 int라면 디스크 상에서 4바이트를 차지할 것이고, long이나 double이면 8바이트가 된다.
 2. 도큐먼트의 크기나 구조를 바꾸는 업데이트다. BSON 도큐먼트는 문자 그대로 바이트 배열로 표현되고, 처음 네 바이트로 해당 도큐먼트의 크기를 나타낸다.따라서 도큐먼트에 대해 $push 연산자를 사용하면 도큐먼트의 전체 크기와 구조를 변경하게 된다.이것은 곧 전체 도큐먼트를 디스킁 다시 쓰기를 해야 한다는 의미다.
 3. 업데이트는 도큐먼트를 다시 쓰기 할때의 업데이트다.도큐먼트가 확장되고 디스크에서 할당된 공간 내에 들어갈 수 없으면 다시 쓰기를 해야 할뿐만 아니라 새로운 공간으로 이동까지 해야 한다.이것이 자주 발생하면 리소스를 많이 필요로 하기 쉽다.MongoDB에서는 컬렉션에 대해 패딩 지수를 동적으로 제어함으로써 이 문제를 완화하고자 한다.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>쿼리와 집계</title>
      <link>http://kwsstudy.github.io/post/%EC%BF%BC%EB%A6%AC%EC%99%80-%EC%A7%91%EA%B3%84/</link>
      <pubDate>Sun, 20 Nov 2016 12:00:00 +0900</pubDate>
      
      <guid>http://kwsstudy.github.io/post/%EC%BF%BC%EB%A6%AC%EC%99%80-%EC%A7%91%EA%B3%84/</guid>
      <description>

&lt;h3 id=&#34;목표:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;목표&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Mongodb 질의 연산자를 자세히 다뤄보자.&lt;/li&gt;
&lt;li&gt;맵-리듀스 함수를 중심으로 데이터에 대해 집계를 실행하는 방법을 살펴 보자.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;상품-카테고리-리뷰-쿼리:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;상품, 카테고리, 리뷰 쿼리&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;상품 페이지를 가져오는 쿼리 예&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//1. slug가 whell-barrow-9092인 상품을 찾는다.
db.products.findOne({&#39;slug&#39;:&#39;whell-barrow-9092&#39;}) 

//2. 해당 상품의 카테고리 정보를 가져온다.
db.categories.findOne({&#39;_id&#39;:product[&#39;main_cat_id&#39;]}) 

//3. 상품 리뷰를 불러온다.
db.reviews.find({&#39;product_id&#39;:product[&#39;_id&#39;]}) 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;findOne()과 find()의 차이점&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;findOne()은 도큐먼트를 리턴한다.하나의 도큐먼트를 얻고자 할 때 사용한다.&lt;/li&gt;
&lt;li&gt;find()는 커서객체를 리턴한다. 여러개의 도큐먼트를 리턴 할 때 사용한다.&lt;/li&gt;
&lt;li&gt;findOne()은 db.collection.find().limit(1)과 동일하다&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;페이지를 나누기위해 Mongodb는 skip()과 limit() 옵션을 제공한다.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//1. 0~12번째 상품 리뷰를 불러온다.
db.reviews.find({&#39;product_id&#39;:product[&#39;_id&#39;]}).skip(0).limit(12)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;정렬은 sort() 함수를 사용한다.&lt;/li&gt;
&lt;li&gt;1은 오름차순 -1은 내림차순 정렬.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//1. 0~12번째 상품 리뷰를 추천수가 많은 순서로 불러온다.
db.reviews.find({&#39;product_id&#39;:product[&#39;_id&#39;]}).sort({helpful_votes:-1}).skip(0).limit(12)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;특정 키정보가 없는 도큐먼트만 가져오고 싶을때는 null(책은 nil이라고 되어있는데 지금 버전에서는 null인듯)을 사용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//1. parent_id정보가 없는 카테고리 가져오기
db.category.find({&#39;parent_id&#39;:null})
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;유저와-오더:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;유저와 오더&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;findOne()을 사용하면 도큐먼트를 결과값으로 받고, 결과가 없으면 아무것도 리턴하지 않는다.&lt;/li&gt;
&lt;li&gt;필요하지 않은 필드까지 가져옴으로써 성능에 문제가 생길수 있다.&lt;/li&gt;
&lt;li&gt;도큐먼트에서 가져올 필드를 제한하는 방법으로, 두번째 파라미터로 필요한 필드는 값을1 필요없는 필드는 값을0으로 지정해준다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//1. _id정보만 가져오기
db.category.findOne({slug:&#39;gardening-tools&#39;},{_id:1})
//{ &amp;quot;_id&amp;quot; : ObjectId(&amp;quot;6a5b1476238d3b4dd5000048&amp;quot;) }

//2. _id정보만 제외하고 가져오기
db.category.findOne({slug:&#39;gardening-tools&#39;},{_id:0})
/*
{
	&amp;quot;slug&amp;quot; : &amp;quot;gardening-tools&amp;quot;,
	&amp;quot;ancestors&amp;quot; : [
		{
			&amp;quot;name&amp;quot; : &amp;quot;Home&amp;quot;,
			&amp;quot;_id&amp;quot; : ObjectId(&amp;quot;8b87fb1476238d3b4dd50003&amp;quot;),
			&amp;quot;slug&amp;quot; : &amp;quot;home&amp;quot;
		},
		{
			&amp;quot;name&amp;quot; : &amp;quot;Outdoors&amp;quot;,
			&amp;quot;_id&amp;quot; : ObjectId(&amp;quot;9a9fb1476238d3b4dd500001&amp;quot;),
			&amp;quot;slug&amp;quot; : &amp;quot;outdoors&amp;quot;
		}
	],
	&amp;quot;parent_id&amp;quot; : ObjectId(&amp;quot;9a9fb1476238d3b4dd500001&amp;quot;),
	&amp;quot;name&amp;quot; : &amp;quot;Gardening Tools&amp;quot;,
	&amp;quot;description&amp;quot; : &amp;quot;Gardening gadgets galore!&amp;quot;
}
*/
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;RDBMS의 like와 같은 쿼리는 정규식을 이용한다&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//1. 이름이 ba로 시작하는 사용자 찾기
db.users.find({last_name:/^ba/})
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;mongodb-질의어:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;MongoDB 질의어&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;RDBMS의 AND 절과 같은 질의는 find({name:&amp;lsquo;park&amp;rsquo;, age:33})&lt;/li&gt;
&lt;li&gt;RDBMS의 &amp;lt;, &amp;lt;=, &amp;gt;, &amp;gt;= 는 각 $gt, $gte, $lt, $lte이다&lt;/li&gt;
&lt;li&gt;$in은 검색 키워드와 일치하는 값이 하나라도 있을경우 해당 도큐먼트를 리턴한다.&lt;/li&gt;
&lt;li&gt;$nin은 검색 키워드와 일치하지 않은 도큐먼트를 리턴해준다.&lt;/li&gt;
&lt;li&gt;$all은 검색키워드가 모두 일치하는 도큐먼트를 리턴해준다.&lt;/li&gt;
&lt;li&gt;$in, $all은 인덱스를 사용하지만, $nin은 인덱스를 사용하지 않는다.&lt;/li&gt;
&lt;li&gt;$ne 단일,배열 값에 상관없이 지정한 값이 아닌 도큐먼트를 찾아준다.&lt;/li&gt;
&lt;li&gt;$ne는 인덱스를 사용하지 않는다.&lt;/li&gt;
&lt;li&gt;$not은 정규 표현식 쿼리로부터 얻은 결과의 여집합을 리턴한다.&lt;/li&gt;
&lt;li&gt;$not을 사용 할 때는 연산자나 정규표현식에 부정형이 존재하지 않을때 사용한다.&lt;/li&gt;
&lt;li&gt;$or는 2개의 서로다른 키에대한 논리합을 표현한다.&lt;/li&gt;
&lt;li&gt;결과값이 가능한 같은 키에대한것이라면 $in을 이용하자.&lt;/li&gt;
&lt;li&gt;Mongodb는 고정된 스키마가 없기때문에 특정키를 가지고 있는지 확인해야 할 경우 $exists를 이용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;서브도큐먼트-매칭:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;서브도큐먼트 매칭&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;아래와 같이 도큐먼트 안에 도큐먼트가 포함된 경우 서브도큐먼트에 접근하기 위해 닷(.)을 이용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;// address는 서브 도큐먼트로 zipcode에 접근할 때는 address.zipcode 처럼 접근한다. 
{
_id : ObjectId(&amp;quot;5c32cji23cij3c&amp;quot;),
name : &amp;quot;niee&amp;quot;,
  address : {
    zipcode : &amp;quot;12345&amp;quot;,
    home : &amp;quot;Inchone&amp;quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;배열:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;배열&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;배열로 이루어진 키에도 인덱스를 이용할 수 있다.&lt;/li&gt;
&lt;li&gt;닷 표기법을 이용하여 특정 원소에 접근 가능하다. ex)arrayKey.0// 0번째 원소&lt;/li&gt;
&lt;li&gt;같은 키를 갖는 오브젝트 배열에서 key.0.name을 사용하면 첫번째 오브젝트의 name에 접근하고 key.name을 사용하면 모든 오브젝트 배열에 접근하여 name을 가져온다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;자바스크립트:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;자바스크립트&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;쿼리 툴로도 표현할 수 없다면, 자바스크립트를 작성하여 사용할 수 있다.&lt;/li&gt;
&lt;li&gt;자바스크립트는 $where연산자와 함께 함수를 작성하는데 함수내부의 this는 현재 도큐먼트를 가리킨다.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//1. helpful_votes &amp;gt; 3 도큐먼트 찾기
db.reviews.find({$where : &amp;quot;function(){return this.helpful_votes &amp;gt; 3;}&amp;quot;})

//2. 더 간단하게 아래처럼 가능
db.reviews.find({$where : &amp;quot;this.helpful_votes &amp;gt; 3&amp;quot;})
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;자바스크립트를 이용할 경우 인덱스를 사용하지 못해 발생하는 성능 저하 문제와 함께, SQLInjection에 취약해진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;정규-표현식-그밖의-쿼리-연산자-프로젝션-정렬은-책을-찹조-121-124:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;정규 표현식, 그밖의 쿼리 연산자, 프로젝션, 정렬은 책을 찹조 121~124&lt;/h3&gt;

&lt;h3 id=&#34;스킵과-리미트:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;스킵과 리미트&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;skip을 사용시 지정한 값만큼 도큐먼트를 스캔해야 하기 때문에 큰 값이 넘어가면 쿼리가 비효율 적일 수 있다.&lt;/li&gt;
&lt;li&gt;좀더 나은 쿼리를 위해 skip은 생략하고, 다음 결과 값이 시작되는 범위 조건을 추가 하는 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;group:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;group&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;대부분의 RDBMS는 합계, 평균, 편차와같은 내장 집계함수를 많이 제공하지만, Mongodb에는 구현될 때까지 group,map-reduce를 사용해야한다.&lt;/li&gt;
&lt;li&gt;group()은 최소한 3개의 파라미터를 받는다.&lt;/li&gt;
&lt;li&gt;첫번째 파라미터 key는 데이터를 어떻게 그룹으로 묶을것인지를 지정한다.&lt;/li&gt;
&lt;li&gt;두번째 파라미터는 리듀스(reduce funciton) 함수로, 결과 값에 대해 그룹으로 묶는 자바스크립트 함수다.&lt;/li&gt;
&lt;li&gt;세번짜 파라미터는 각 키의 값에 대해 처음 반복할 때 리듀스 함수에게 제공하는 초기 도큐먼트다.&lt;/li&gt;
&lt;li&gt;group은 20,000개 까지 허용되는듯?(group이 20,000개 넘어가니 group() can&amp;rsquo;t handle more than 20000 unique keys 에러 발생)&lt;/li&gt;
&lt;li&gt;group은 많은 경우 맵-리듀스보다 빠르기 때문에 좋은 선택일 수 있다.&lt;/li&gt;
&lt;li&gt;key : 그룹으로 나누는 기준이 되는 키를 표현한 도큐먼트. 복합키도 가능.&lt;/li&gt;
&lt;li&gt;keyf : 그룹을 위한 키를 계산을 통해 만들어야 하는경우 필요한 자바스크립트 함수. key를 지정하지 않으면 반드시 필요.&lt;/li&gt;
&lt;li&gt;initial : 집계 결과의 초기값으로 사용되는 도큐먼트.(필수)&lt;/li&gt;
&lt;li&gt;reduce : 집계 기능을 수행하는 함수.현재 도큐먼트와, 집계결과를 저장하는 도큐먼트 2개의 파라미터를 받는다.리턴할 필요가 없다.(필수)&lt;/li&gt;
&lt;li&gt;cond : 집계를 수행하기 위한 도큐먼트를 필터링 하는 쿼리 셀렉터.&lt;/li&gt;
&lt;li&gt;finalize : 결과값을 리턴하기전 각 도큐먼트에 적용되는 함수.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//1. 사용자별 리뷰 수와 리뷰 평점
db.reviews.group({
  key : {user_id : true},
  initial : {reviews : 0, votes : 0.0},
  reduce : function(doc, aggregator){
    aggregator.reviews +=1;
    aggregator.votes += doc.votes;
  },
  finalize : function(doc){
    doc.average_votes = doc.votes / doc.reviews;
  }
})
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;맵-리듀스-map-reduce:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;맵-리듀스(map-reduce)&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;맵-리듀스는 group의 좀더 유연한 버전으로 생각할 수 있다.&lt;/li&gt;
&lt;li&gt;그룹 키에 대한 세밀한 제어를 할수 있다.&lt;/li&gt;
&lt;li&gt;새 컬렉션에 결과를 저장하는 것 같은 다양한 출력 옵션을 가질 수 있다.&lt;/li&gt;
&lt;li&gt;맵-리듀스는 샤드 구성에서 대량의 데이터를 반복 처리하기 위해 필요한 분산된 어그리 게이터를 지원한다.&lt;/li&gt;
&lt;li&gt;map : 각 도큐먼트에 적용하는 자바스크립트 함수. 집계에 사용 할 키와 값을 선택하기 위해 emit()을 의무적으로 호출 해야함.&lt;/li&gt;
&lt;li&gt;reduce : 키와 값의 리스트를 받는 자바스크립트 함수. 반드시 받은 값과 같은 구조의 값을 리턴 해야함.&lt;/li&gt;
&lt;li&gt;query : 매핑될 컬렉션을 필터하는 퀄리 셀렉터, group의 cond와 같은 기능.&lt;/li&gt;
&lt;li&gt;sort : 쿼리에 적용할 정렬 조건. limit옵션과 사용할때 유용&lt;/li&gt;
&lt;li&gt;limit : 쿼리와 정렬에 적용되어 결과 값의 개수를 제한하는 정수.&lt;/li&gt;
&lt;li&gt;out : 결과가 어떻게 리턴되는지를 결정.(자세한 설명은 134p참조)&lt;/li&gt;
&lt;li&gt;finalize : 리듀스가 완료된 후 각 결과 도큐먼트에 적용될 자바스크립트 함수.&lt;/li&gt;
&lt;li&gt;scope : map, reduce, finalize 함수에 의해 액세스 되는 전역 변서의 값을 지정하는 도큐먼트.&lt;/li&gt;
&lt;li&gt;verbose : true일 경우 맵-리듀스 실행 시간에 대한 통계 데이터를 리턴.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//1. 2010년 이후 월 판매액을 구하여 total컬렉션에 저장하기
map = function(){
  var shipping_month = this.purchase_date.getMonth() + &#39;-&#39; + this.purchase_date.getFullYear();
  var tmpItems = 0;
  this.line_items.forEach(function(item){
    tmpItems += item.quantity;
  });
  
  emit(shipping_month, {order_total : this.sub_total, items_total : tmpItems });
}

reduce = function(key, values){
  var tmpTotal = 0;
  var tmpItems = 0;

  tmpTotal += doc.order_total;
  tmpItems += doc.items_total;
  
  return({total : tmpTotal, items : tmpItems});
}

filter = {purchase_date : {$gte : new Date(2010, 0, 1)}}

db.orders.mapReduce(map, reduce, {query : filter, out : &#39;totals&#39;});
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;distinct:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;distinct&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;특정 키에대한 고유 값을 얻기 위한 가장 간단한 툴.&lt;/li&gt;
&lt;li&gt;단일 키와 배열 값을 갖는 키에 모두 적용된다.&lt;/li&gt;
&lt;li&gt;전체 컬렉션에 수행되지만, 두번째 파라메터로 쿼리 셀렉터를 이용하여 제한가능.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//1. product 컬렉션의 tags 키의 값만 얻기
db.products.distinct(&amp;quot;tags&amp;quot;)

//2. product 컬렉션의 name이 car인 tags 키의 값만 얻기
db.products.distinct(&amp;quot;tags&amp;quot;,{name:&#39;car&#39;})
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;group과-distinct는-16mb가-넘는-결과-값은-리턴하지-못한다-이럴경우-맵-리듀스를-이용하여-컬렉션에-저장한다:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;group과 distinct는 16MB가 넘는 결과 값은 리턴하지 못한다. 이럴경우 맵-리듀스를 이용하여 컬렉션에 저장한다.&lt;/h4&gt;

&lt;h4 id=&#34;group과-맵-리듀스의-한계는-속도다-자바스크립트-인터프리터-때문에-대량의-데이터에-대해-속도가-보장되지-못한다:2f2307b1bbb44d3e18efdfe8af35ab77&#34;&gt;group과 맵-리듀스의 한계는 속도다. 자바스크립트 인터프리터 때문에 대량의 데이터에 대해 속도가 보장되지 못한다.&lt;/h4&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;http://cinema4dr12.tistory.com/entry/Aggregation-MapReduce&#34;&gt;맵-리듀스 설명 잘된 곳&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>도큐먼트 지향 데이터</title>
      <link>http://kwsstudy.github.io/post/%EB%8F%84%ED%81%90%EB%A8%BC%ED%8A%B8-%EC%A7%80%ED%96%A5-%EB%8D%B0%EC%9D%B4%ED%84%B0/</link>
      <pubDate>Sun, 20 Nov 2016 11:00:00 +0900</pubDate>
      
      <guid>http://kwsstudy.github.io/post/%EB%8F%84%ED%81%90%EB%A8%BC%ED%8A%B8-%EC%A7%80%ED%96%A5-%EB%8D%B0%EC%9D%B4%ED%84%B0/</guid>
      <description>

&lt;p&gt;도큐먼트 지향 데이터&lt;/p&gt;

&lt;h2 id=&#34;4-1-스키마-설계-원리:54d1105edd70474019e96d562a258776&#34;&gt;4.1 스키마 설계 원리&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;이론에 따라 스키마를 설계해야 하지만 실제에서는 이론을 융통성 있게 적용해야 한다.&amp;rdquo; (이에 따른 제기할수 있는 질답)

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;데이터의 기본 단위는 무엇인가?&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;RDBMS에서는 행과 열로 이루어진 테이블이 있다. 키(값) 저장 시스템에서는 키와 값을 갖는데, 여기서 값은 비구조적이다. MongDB에서는 데이터               기본적 단위가 BSON도큐먼트다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;데이터를 어떻게 쿼리하고 업데이트할 것인가?&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;RDBMS는 임의 쿼리와 조인이 특징. MongDB 또한 임의 쿼리를 허용하지만 조인은 지원하지 않는다. (간단한 키(값) 저장 시스템은 하나의 키에 대해서만 값을 가져올 수 있다.&lt;/li&gt;
&lt;li&gt;MongDB는 트랜잭션을 지원하지는 않지만 복잡한 도큐먼트의 내부 구조에 대해 수행할 수 있는 원자적인 업데이트를 다양하게 지원한다.&lt;/li&gt;
&lt;li&gt;요점은 최적의 데이터 모델을 설계하려면 데이터베이스의 특징을 이해하고 있어야 한다는 것이다.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;애플리케이션의 액세스 패턴은 무엇인가?&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;애플리케이션의 요구사항이 무엇인지 정확히 파악해야한다.&lt;/li&gt;
&lt;li&gt;읽기/쓰기 비율은 어떻게 되는가? 어떤 쿼리가 필요한가? 데이터는 어떻게 업데이트가 되는가? 동시성 문제는 어떻게 되는가? 데이터는 어느 정도로 잘 구조화할 수 있는가?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;##4.2.1 상품과 카테고리
  - 도큐먼트에 대한 URL을 생성할 때는 슬러그(slug) 필드를 만들 것을 권한다. 그러한 필드에 대해서는 고유 인덱스를 만들어서 프라이머리 키로 사용할 수있다.
  - product 입력 데이터는 샘플 소스 참조
  - db.products.ensureIndex({slug:1}, {unique:true}) / slug 생성, 고유인덱스
  - 유니크 키
  - @products.insert({:name =&amp;gt; &amp;ldquo;Extra Large Wheel Barrow&amp;rdquo;},
                      :sku =&amp;gt; &amp;ldquo;9092&amp;rdquo;,
                      :slug =&amp;gt; &amp;ldquo;wheel-barrow-9092&amp;rdquo;},
                      :safe =&amp;gt; true)
  - :safe =&amp;gt; true 라고 지정 위 삽입문이 예외를 발생하지 않고 성공한다면 슬러그 값이 고유한 값이라는 것을 알 수 있다.
    예외가 발생하면 새로운 슬러그로 다시 시도해야 할 것이다.
  - detail 이라는 키는 여러가지 상품에 대한 자세한 정보를 갖는 서브도큐먼트를 가리킨다 (detail 속성은 이러한 동적인 속성을 갖기에 적합)
  - MongDB는 조인을 지원하지 않기 때문에 다대다 관계를 위해서는 다른 어떤것이 필요하다.
  - 상품 샘플 데이터를 보면 category_ids 라는 필드가 객체 ID를 가지고 있는 것을 볼 수 있다. 각 객체 ID는 카테고리 도큐먼트의 _id 필드에 대한 래퍼런스다.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;doc =
{  _id: ObjectId(&amp;quot;6a5b1476238d3b4dd5000048&amp;quot;),
   slug: &amp;quot;gardening-tools&amp;quot;,
   ancestors: [{ name: &amp;quot;Home&amp;quot;,
                 _id:  ObjectId(&amp;quot;8b87fb1476238d3b4dd50003&amp;quot;),
                 slug: &amp;quot;home&amp;quot;
                },

                { name: &amp;quot;Outdoors&amp;quot;,
                  _id:  ObjectId(&amp;quot;9a9fb1476238d3b4dd500001&amp;quot;),
                  slug: &amp;quot;outdoors&amp;quot;
                }
   ],

   parent_id: ObjectId(&amp;quot;9a9fb1476238d3b4dd500001&amp;quot;),

   name: &amp;quot;Gardening Tools&amp;quot;,
   description: &amp;quot;Gardening gadgets galore!&amp;quot;,
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;책의 예제에서는 RDBMS의 in절 사용법이 루비로 나와있는데 자바에서 in절 사용법은
&lt;a href=&#34;http://rockfactory.tistory.com/81&#34;&gt;http://rockfactory.tistory.com/81&lt;/a&gt; 를 참조&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;4.2.2 유저와 오더
  - 유저와 오더로 일대다의 관계를 설명 할 수 있다.
  - 유저는 하나 이상의 오더를 가지고 있다.
  - 두번째 속성인 user_id는 유저의 id값을 가지고 있다.
  - db.orders.find({user_id:user[&amp;rsquo;_id&amp;rsquo;]}) / 어느 한 유저가 주만한 모든 오더를 조회
  - var user_id = order[&amp;lsquo;user_id&amp;rsquo;]
    db.users.find({_id:user_id}) /특정 오더에 대한 유저의 도큐먼트를 얻기위한 쿼리
  - 따라서 오더와 유저사이에 존재하는 일대다 관계가 객체ID를 레퍼런스로 사용해서 쉽게 구현이 가능하다&lt;/p&gt;

&lt;p&gt;##4.2.3 상품평
  - 각 상품은 하나 이상의 리뷰를 가지고있다. 여기에서 관계는 review_id라는 객체 ID래퍼런스로 표현
  - review_template.js 참조
  - MongoDB에서는 조인이 없기 때문에 두 가지 방법 중 한가지를 써야한다.
    각 리뷰마다 유저 컬렉션에 대해 질의하거나 비정규화를 해야한다.
  - 이것은 유저네임을 수정할 경우, 유저네임이 들어가 있는 모든 도큐먼트를 수정해야 하기 때문에 비용이 더 많이들어간다는 것을 의미하지만, 이런
    경우는 드물기 때문에 이렇게 설계하는게 타당하다. (일반적으로 유저네임명(uniqe)값을 수정하는 일은 없기에)
  - 추천수를 배열로 저장한 이유는 한 유저가 두번의 추천을 입력하는것을 방지
  - 추천수를 저장하는것은 추천수에 따른 정렬를 위함&lt;/p&gt;

&lt;p&gt;##4.3 실제적 세부사항: 데이터베이스, 컬렉션, 도큐먼트
  - 데이터베이스, 컬렉션, 도큐먼트를 사용하는 것에 대해 실제 세부사항을 살펴보도록하자.
  - MongDB가 데이터 파일을 어떻게 할당하는지, 혹은 도큐먼트 내에서 어떤 데이터 타입이 허용되는지, 또는 캡드(?) 컬렉션을 사용하는 것이 어떤 이점이 있는지 알아보자&lt;/p&gt;

&lt;p&gt;##4.3.1 데이터베이스
  - 데이터베이스 관리
    - MongoDB에서는 데이터베이스를 생성하는 별도의 다른 방법이 없다.
    - 대신 데이터베이스 내의 컬렉션에 쓰기를 하면 자동으로 생성된다.
    - 상품컬렉션에 save를 호출할 때 (insert) MongoDB에게 garden.products 네임스페이스에 상품 도큐먼트를 저장하라고 명령
      네임스페이스가 존재하지 않으면 네임스페이스가 먼저 생성되고, 이 과정에서 garden 데이터베이스가 디스크에 할당된다
    - 데이터베이스를 삭제하는 쉘 명령어는
      use garden
      db.dropDatabase();
    - 데이터 베이스를 지우고 나면 취소할 수 없기 때문에 조심해야 한다.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;데이터 파일과 할당

&lt;ul&gt;
&lt;li&gt;데이터베이스가 생성될 때 MongoDB는 몇가지 데이터 파일을 디스크에 할당한다.
모든 컬렉션, 인덱스, 데이터베이스에 대한 메타데이터가 여기에 저장된다.&lt;/li&gt;
&lt;li&gt;이 파일들은 mongod를 시작할 때 dbpath에서 지정한 디렉터리에 저장된다. sudo mongod &amp;ndash;dbpath /data/db &amp;;&lt;/li&gt;
&lt;li&gt;dbpath가 지정되지 않으면 mongod는 모든 파일을 /data/db에 저장한다

&lt;ul&gt;
&lt;li&gt;mongod.lock : 서버의 프로세스 ID를 저장 (비정상적으로 셧다운된 후에 다시 부팅되는 경우가 아니라면 이파일을 절대 지우거나 변경하면 안된다 복구 프로세스는 10장에서 설명) garden 데이터 베이스가 처음 생성될때 garden.ns라는 파일이 가장 먼저 만들어진다. 파일 확장자 인 ns는 네임스페이스를 의미, 데이터베이스 내의 모든 컬렉션과 인덱스는 자신만의 네임스페이스를 갖는데, 각 네임스페이스에 대한 메타데이터를 이 파일에 저장.
디폴트로 크기가 16MB로 고정되어 있어서 약 24,000개의 네임스페이스를 저장할 수 있다 이것은 한 데이터베이스에서 인덱스와 컬렉션의 개수가 24,000을 넘어설 수 없다는 것을 의미. 더 많이 필요할 경우에는 &amp;ndash;nssize옵션을 사용해서 이 제한을 조정할 수 있다.&lt;/li&gt;
&lt;li&gt;garden.0(64MB), 1(128MB) : MongoDB는 최대한 많은 데이터가 디스크에 연속적으로 저장되도록 미리 할당 (연산이 디스크의 여기저기에 흩어져 있는 데이터가 아니라 인접된 데이터에 대해 수행되도록 하기위함)&lt;/li&gt;
&lt;li&gt;stats 명령을 사용해서 사용하는 공간과 할당된 공간을 언제라도 확인할수있다.  db.status&lt;/li&gt;
&lt;li&gt;filesize필드는 이 데이터베이스에 대해 할당된 파일의 전체 크기를 보여준다 garden.0 + garden.1 파일의 용량의 합&lt;/li&gt;
&lt;li&gt;dataSize : 데이터베이스에서 BSON오브젝트의 실제크기
storageSize : 컬렉션이 증가할 것을 대비한 여분의 공간과 삭제되었지만 아직 할당되지 않은 공간
indexSize : 데이터베이스 인덱스의 전체크기를 보여준다. 모든 인덱스가 램에 있을 때 데이터베이스 성능이 최적이 되기 때문에 indexSize 값을 주의 깊게 봐야한다. (7장과 10장에서 성능과 관계된 문제를 해결하기위한 기법들을 소개할때 자세히 설명)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;##4.3.2 컬렉션
  - 컬렉션은 구조적으로 혹은 개념적으로 유사한 도큐먼트를 담고 있는 컨테이너이다.
  - 컬렉션 관리
    - 컬렉션 생성 : db.createCollection(&amp;ldquo;users&amp;rdquo;)
    - 컬렉션 생성시 크기를 미리 할당하는 옵션 : db.createCollection(&amp;ldquo;user&amp;rdquo;, {size:20000})
    - 컬렉션의 이름은 숫자와 알파벳 또는 &amp;ldquo;.&amp;rdquo; 으로 만들 수 있으나 반드시 알파벳이나 숫자로 시작해야한다.
    - 내부적으로 컬렉션 이름에는 자신이 속한 데이터베이스의 이름이 포함돼 있다.
    - 컬렉션의 전체 이름, 즉 네임스페이스는 128자 이내여야 한다
    - 컬렉션 이름에 &amp;ldquo;.&amp;ldquo;을 사용하여 일종의 가상 네임스페이스를 만드는 것이 유용할 때가 있다.
      예를들어 products.categories, products.images, products.reviews
    - 하지만 이것은 단지 편의를 위한 것이고 데이터베이스는 컬렉션 이름이 &amp;ldquo;.&amp;ldquo;을 포함해도 다른 컬렉션과 똑같이 처리한다는 점을 명심
    - 컬렉션의 이름변경 : db.products.renameCollection(&amp;ldquo;store_products&amp;rdquo;)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;캡드 컬렉션

&lt;ul&gt;
&lt;li&gt;높은 성능의 로깅 기능을 위해 설계되었다&lt;/li&gt;
&lt;li&gt;고정된 크기를 갖는점이 일단 컬렉션과 다르다&lt;/li&gt;
&lt;li&gt;공간이 더이상 없게되면 도큐먼트를 삽입할 때 컬렉션에 추가된 지 가장 오래된 도큐먼트를 덮어쓰게된다.&lt;/li&gt;
&lt;li&gt;이 기능은 수동으로 컬렉션의 오래된 데이터를 지워야한 하는 번거로움을 없애준다.&lt;/li&gt;
&lt;li&gt;도큐먼트를 삽입된 순서로 정렬하는 점과 인덱스를 생성하지 않는다는 점 외에도 캡트 컬렉션에서는 특정 CRUD연산이 제한되는 점 또한 알아야한다 개별도큐먼트를 지울 수 없고 도큐먼트의 크기가 커기는 결과를 초래하는 업데이트를 수행할 수 없다. (캡드 컬력센은 로깅을 위해 만들어진 것, 이것들을 구현하기위해서는 오래된 도큐먼트의 age를 핸들링하는 코드가 복잡해지기 떄문)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;시스템 컬렉션

&lt;ul&gt;
&lt;li&gt;MongDB 내부에서 컬렉션을 부분적으로 사용, 언제나 존재&lt;/li&gt;
&lt;li&gt;system.namespace와 system.indexes다.
system.namespace 는 현재 사용 중인 데이터 베이스에서 정의돈 모든네임스페이스를 보여준다&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;-4.3.3 도큐먼트와 인서트
    - 모든 도큐먼트는 MongoDB에 저장하기 전에 BSON으로 시리얼라이즈 되어야하고, BSON으로부터 프로그래밍 언어로 표현되는 도큐먼트 형식으로 디시리얼라이즈 된다. 예를들어 캡드 컬렉션에 대해 설명할 때 샘플 도큐먼트 크기가 약 100바이트 정도라고 추정했었는데 루비, 자바 등등 드라이버의 BSON 시러얼라이저를 이용하면 그 가정이 맞는지 확인할 수 있다.
    - 문자열
      - 모든 문자열은 UTF-8 형식이어야 한다.
      - MongoDB로 변환하기 전에 미리 UTF-8로 변환을 하든지, 그것이 여의치 않을 경우 텍스트를 BSON바이너리 타입으로 저장하면 된다.
    - 숫자
      - BSON은 double, int, long의 세 가지 수 타입을 규정
      - IEEE실수와 signed정수를 8바이트 까지 인코딩할 수 있다는 것을 의미, 자바스크립트는 Number라는 수 타입을 하나만 가지고 있는데, 이것은 IEEE double 에 해당.
      - 따라서 셸을 통해 정수 값으로 저장하고 싶다면 NumberLong()이나 NumberInt를 써서 정수라는 것을 명시해야한다.
    - 날짜와 시간
      - BSON datetime 타입은 시간이나 날짜에 관련된 값을 저장하는 데 사용된다.
      - 시간은 signed64비트 정수를 사용해서 UTC로 유닉스 에폭이후 지나간 밀리초로 표현한다.(유닉스 에폭은 1970년 1월 1일 자정)
      - 주의사항 : 자바스크립트에서 날짜를 생성하는 경우에는 월을 표현할 때 0부터 시작한다는점 ( new Date(2011, 5 ,11) -&amp;gt; 2011년 6월 11일), 루비 드라이버를 이용해서 시간 데이터를 저장할 경우 BSON datetime 은 타임 존을 인코드할 수 없기 때문에 이 데이터를 가지고 있는 date 클래스를 사용할 수 없다.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- 커스텀 타입 
  - 시간을 반드시 타임존과 함께 저장해야 할 필요가 있을때 BSON타입을 사용해서 가상의 타입을 만들어낼 수 있다.
- 도큐먼트 크기에 대한제약
  - 도큐먼트의 최대 크기는 16MB이다 
  - 1. 개발자가 효율적이지 못한 데이터 모델을 생성하는 것을 막기위함
  - 2. 성능과 관계
  - 일반적으로 큰 객체를 가지고 있다면 데이터 모델을 수정해서 한두 개의 컬렉션을 추가로 만들어 분할하는 것이 더 낫다. 이미지나 비디오같이 단순하게 크기가 큰 바이너리 객체를 저장하는 것은 조금 다른 경우다. 대용량 바이너리 데이터를 처리하기 위한 기법은 부록 c를 참조...

- 대량 삽입 연산
  - 모든 드라이버에서는 여러 개의 도큐먼트를 동시에 삽입하는 것이 가능하다. (초기화할 때 대량의 데이터를 임포트 한다든지, 다른 데이터 베이스 시스템에서 MongoDB로 옮겨운 경우 등 여러 상황에서 유용)
  - 미리 다수의 도큐먼트 배열을 만들고 insert메소드에 전체 도큐먼트의 배열을 넘겨준다.
  - 대량 삽입을 가장 효율적으로 하려면 16MB 제한 이하로 해야한다.
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>